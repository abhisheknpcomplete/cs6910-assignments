{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f85e9d-215f-45c6-95ad-d56e6e3d3759",
   "metadata": {
    "id": "33f85e9d-215f-45c6-95ad-d56e6e3d3759"
   },
   "source": [
    "#### CS20M059 Shibobrota Das | CS20M007 Abhishek Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700a5ec-7c66-45f5-9539-a593bb36ddc6",
   "metadata": {
    "id": "6700a5ec-7c66-45f5-9539-a593bb36ddc6"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b51cb32-fdbd-4f91-96ca-91ee41122b6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b51cb32-fdbd-4f91-96ca-91ee41122b6b",
    "outputId": "7ba68143-c4f2-49b5-d083-8b245fd9b02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 686kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08fb4b5-e93b-4c82-bc45-e2a22a7dee95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a08fb4b5-e93b-4c82-bc45-e2a22a7dee95",
    "outputId": "55823e8a-5d43-47e4-f211-b8773fea1280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.8MB 8.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 133kB 51.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 174kB 38.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
      "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c70406c-fe4d-43f1-93a4-9dc617b301da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c70406c-fe4d-43f1-93a4-9dc617b301da",
    "outputId": "f04d4e3f-585e-4d71-ada8-83db1612d003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.5.0\n",
      "Using tensorflow Addons: 0.13.0\n",
      "Using keras: 2.5.0\n",
      "Using pandas: 1.2.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "import wandb\n",
    "# import nltk\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using tensorflow Addons:\",tfa.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf43393-e89f-46f4-a711-f2e7078e9e85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "ddf43393-e89f-46f4-a711-f2e7078e9e85",
    "outputId": "928563a1-ca11-4647-e59b-2ecd1757b9ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ieo5mk6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2ieo5mk6). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">crisp-water-211</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203\" target=\"_blank\">https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/6g6t6l2c\" target=\"_blank\">https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/6g6t6l2c</a><br/>\n",
       "                Run data is saved locally in <code>/content/drive/My Drive/A3-checkpoints/wandb/run-20210520_185916-6g6t6l2c</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(6g6t6l2c)</h1><iframe src=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/6g6t6l2c\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa6c5de0bd0>"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.init(project='Assignment 3', entity='iitm-cs6910-jan-may-2021-cs20m059-cs20m007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd226e1-96b2-4440-a310-15a8cf2f0035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd226e1-96b2-4440-a310-15a8cf2f0035",
    "outputId": "77f6e150-a1e9-4fdd-8fbb-91afc05dd3de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/DL-A3 Dataset/dakshina_dataset_v1.0/hi\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/My Drive/DL-A3 Dataset/dakshina_dataset_v1.0/hi/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c92d9-374e-4e0f-b2d1-7f17d895cc04",
   "metadata": {
    "id": "559c92d9-374e-4e0f-b2d1-7f17d895cc04"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee85d467-1fac-40d1-a7ca-b00faf2d3d4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee85d467-1fac-40d1-a7ca-b00faf2d3d4b",
    "outputId": "bd5ad0b6-4205-4998-92ae-ee2ef88a1724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ae78d1-de5a-435a-8b39-088bd63f8e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13ae78d1-de5a-435a-8b39-088bd63f8e2c",
    "outputId": "a6d3d8a2-6b85-4b3f-9756-37e8c7af2a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/A3-checkpoints\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/A3-checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6b5e6-844e-4fb9-9eeb-bcedd0cf6fd1",
   "metadata": {
    "id": "caa6b5e6-844e-4fb9-9eeb-bcedd0cf6fd1"
   },
   "source": [
    "#### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fefa85bd-2299-4503-8d29-458451185e8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "fefa85bd-2299-4503-8d29-458451185e8f",
    "outputId": "2c61f86e-47d3-43c6-ab96-6beb9d416cd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33464</th>\n",
       "      <td>राजीव</td>\n",
       "      <td>rajiv</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>एतिहासिक</td>\n",
       "      <td>athihasik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7565</th>\n",
       "      <td>कामयाब</td>\n",
       "      <td>kamyab</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1  2\n",
       "33464     राजीव      rajiv  4\n",
       "5639   एतिहासिक  athihasik  1\n",
       "7565     कामयाब     kamyab  4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e8bdb-9997-43b6-ba7e-e05879c1c4c0",
   "metadata": {
    "id": "627e8bdb-9997-43b6-ba7e-e05879c1c4c0"
   },
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53abf538-55d3-46e0-9532-f0aded169217",
   "metadata": {
    "id": "53abf538-55d3-46e0-9532-f0aded169217"
   },
   "outputs": [],
   "source": [
    "sos = \"@\"\n",
    "eos = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7035ff0-c322-4ef6-98ac-eae0416ad3a7",
   "metadata": {
    "id": "e7035ff0-c322-4ef6-98ac-eae0416ad3a7"
   },
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, batch_size):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch = tf.data.Dataset.from_tensor_slices((self.input_tensor, self.target_tensor)).shuffle(len(self.input_tensor)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce3cd7e2-7e30-44bb-8a27-77dbf944bea0",
   "metadata": {
    "id": "ce3cd7e2-7e30-44bb-8a27-77dbf944bea0"
   },
   "outputs": [],
   "source": [
    "class TransliterationDatatset:\n",
    "    def __init__(self, df_list, batch_size = 64):\n",
    "        \n",
    "        self.input_tokenizer = None\n",
    "        self.target_tokenizer = None\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "        self.batch_size = batch_size\n",
    "        # Load Data\n",
    "        self.load_dataset(df_list)\n",
    "        # Other parameters\n",
    "        self.num_input_tokens = len(self.input_tokenizer.index_word)+1\n",
    "        self.num_target_tokens = len(self.target_tokenizer.index_word)+1\n",
    "        self.max_input_seq_length = np.max([self.train.input_tensor.shape[1], self.val.input_tensor.shape[1], self.test.input_tensor.shape[1]])\n",
    "        self.max_target_seq_length = np.max([self.train.target_tensor.shape[1], self.val.target_tensor.shape[1], self.test.target_tensor.shape[1]])\n",
    "        \n",
    "    def preprocess_word(self, w):\n",
    "        return sos + str(w) + eos\n",
    "    \n",
    "    def print_input(self, tensor):\n",
    "        for t in tensor:\n",
    "            if t != 0:\n",
    "                print(f'{t} ----> {self.input_tokenizer.index_word[t]}')\n",
    "                \n",
    "    def print_target(self, tensor):\n",
    "        for t in tensor:\n",
    "            if t != 0:\n",
    "                print(f'{t} ----> {self.target_tokenizer.index_word[t]}')\n",
    "    \n",
    "    def create_dataset(self, data_frame):\n",
    "        input_words = []\n",
    "        target_words = []\n",
    "        # Shuffle the data_frame before creating dataset\n",
    "        df = data_frame\n",
    "        for i in range(5):\n",
    "            df = shuffle(df)\n",
    "        for x, y in zip(df[1], df[0]):\n",
    "            input_words.append(self.preprocess_word(x))\n",
    "            target_words.append(self.preprocess_word(y))\n",
    "        return (input_words, target_words)\n",
    "    \n",
    "    def load_dataset(self, df_list):\n",
    "        # df_list should have train -> val -> test in sequence\n",
    "        \n",
    "        self.input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        self.target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        \n",
    "        ds_list = []\n",
    "        \n",
    "        for df in df_list:\n",
    "            # Get the words list\n",
    "            (input_words, target_words) = self.create_dataset(df)\n",
    "            # Fit on the set of words\n",
    "            self.input_tokenizer.fit_on_texts(input_words)\n",
    "            self.target_tokenizer.fit_on_texts(target_words)\n",
    "            ds_list.append((input_words, target_words))\n",
    "                    \n",
    "        self.target_tokenizer.index_word.update({0:\" \"})\n",
    "        self.input_tokenizer.index_word.update({0:\" \"})\n",
    "        \n",
    "        input_word_len = []\n",
    "        target_word_len = []\n",
    "        \n",
    "        tensor_list = []\n",
    "        \n",
    "        for i, (input_words, target_words) in enumerate(ds_list):\n",
    "            input_tensor = self.input_tokenizer.texts_to_sequences(input_words)\n",
    "            target_tensor = self.target_tokenizer.texts_to_sequences(target_words)\n",
    "            tensor_list.append((input_tensor, target_tensor))\n",
    "            input_word_len.append(np.max([len(x) for x in input_tensor]))\n",
    "            target_word_len.append(np.max([len(x) for x in target_tensor]))\n",
    "        \n",
    "        for i, (input_tensor, target_tensor) in enumerate(tensor_list):\n",
    "            \n",
    "            input_tensor = pad_sequences(input_tensor, padding='post', maxlen = np.max(input_word_len))\n",
    "            target_tensor = pad_sequences(target_tensor, padding='post', maxlen = np.max(target_word_len))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.train = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            elif i == 1:\n",
    "                self.val = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            else:\n",
    "                self.test = LexDataset(input_tensor, target_tensor, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63b06317-dab4-4455-812e-1b34679e27b1",
   "metadata": {
    "id": "63b06317-dab4-4455-812e-1b34679e27b1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TransliterationDatatset([train_df, val_df, test_df], 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb817ef-9206-4341-807a-4b4db2113340",
   "metadata": {
    "id": "1fb817ef-9206-4341-807a-4b4db2113340"
   },
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1da1956c-d5be-4d10-a263-f565341e5d6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1da1956c-d5be-4d10-a263-f565341e5d6a",
    "outputId": "394e25f3-17c7-45a6-ee13-256b4d740821",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44204, 22), (44204, 21))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset.train.input_tensor.shape, dataset.train.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a008930-d6da-4be0-898c-153f49b8845a",
   "metadata": {
    "id": "3a008930-d6da-4be0-898c-153f49b8845a"
   },
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3c2a7df-ec58-40b6-9ba1-6b7782fdfa0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3c2a7df-ec58-40b6-9ba1-6b7782fdfa0c",
    "outputId": "2de042fe-d861-40da-ace5-00c13b9f70fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 22), (4358, 21))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data\n",
    "dataset.val.input_tensor.shape, dataset.val.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da416c97-6ef6-4855-8968-dfcd1fe8ff5a",
   "metadata": {
    "id": "da416c97-6ef6-4855-8968-dfcd1fe8ff5a"
   },
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa011970-5547-4783-a89d-8ab8c3438fa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa011970-5547-4783-a89d-8ab8c3438fa6",
    "outputId": "cdaff5ef-5447-445e-b40c-acd72b9c82e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4502, 22), (4502, 21))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "dataset.test.input_tensor.shape, dataset.test.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ada4f-733d-4301-93b2-1ade66cde9a8",
   "metadata": {
    "id": "8a7ada4f-733d-4301-93b2-1ade66cde9a8"
   },
   "source": [
    "#### Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bba2c1c4-7fb6-454b-8210-13398ed7406b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bba2c1c4-7fb6-454b-8210-13398ed7406b",
    "outputId": "0b27cbe7-d682-4d8f-9f09-6a8f8d0c050b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 67)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "dataset.num_input_tokens, dataset.num_target_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a249a5-d5ea-46c6-ab4f-a7d0e08b05f3",
   "metadata": {
    "id": "01a249a5-d5ea-46c6-ab4f-a7d0e08b05f3"
   },
   "source": [
    "#### Maximum Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c96afcb-d6ff-4b44-89f2-5d0797709ce4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c96afcb-d6ff-4b44-89f2-5d0797709ce4",
    "outputId": "18aa41f7-c55e-404b-97c7-7945daefb4a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 21)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max seq length\n",
    "dataset.max_input_seq_length, dataset.max_target_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24fd33-e9fd-47c7-be52-62705caf2ebc",
   "metadata": {
    "id": "ef24fd33-e9fd-47c7-be52-62705caf2ebc"
   },
   "source": [
    "#### Example batch - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3c95122-8a50-482b-ae5d-994a74f31765",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3c95122-8a50-482b-ae5d-994a74f31765",
    "outputId": "59ce31d7-118a-4d7d-f58c-3a6c7ce2b8d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 22]), TensorShape([128, 21]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset.train.batch))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc25ddd3-8cd9-4f65-98de-b4f5bddf8c13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc25ddd3-8cd9-4f65-98de-b4f5bddf8c13",
    "outputId": "bc9bd63c-1d72-43c1-d7fe-4afb6358022f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ----> @\n",
      "9 ----> s\n",
      "1 ----> a\n",
      "7 ----> r\n",
      "20 ----> v\n",
      "1 ----> a\n",
      "12 ----> d\n",
      "16 ----> m\n",
      "4 ----> n\n",
      "3 ----> #\n"
     ]
    }
   ],
   "source": [
    "dataset.print_input(example_input_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc385626-2c47-48cf-88c6-a8bce1ab1cdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc385626-2c47-48cf-88c6-a8bce1ab1cdb",
    "outputId": "a5f3e01c-9bd2-4ee2-f3be-0f9d99cb4472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ----> @\n",
      "9 ----> स\n",
      "4 ----> र\n",
      "5 ----> ्\n",
      "16 ----> व\n",
      "20 ----> द\n",
      "15 ----> म\n",
      "6 ----> न\n",
      "2 ----> #\n"
     ]
    }
   ],
   "source": [
    "dataset.print_target(example_target_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81646f07-05bf-4c75-aaf4-ce964bf9e458",
   "metadata": {
    "id": "81646f07-05bf-4c75-aaf4-ce964bf9e458"
   },
   "source": [
    "## Encoder and Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29f2c233-4f9a-471a-8ff9-dfe5950a4963",
   "metadata": {
    "id": "29f2c233-4f9a-471a-8ff9-dfe5950a4963"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, layer_type=\"GRU\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "#         if layer_type == \"LSTM\":\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59648301-2c83-4d6e-b066-3bb2ff53650c",
   "metadata": {
    "id": "59648301-2c83-4d6e-b066-3bb2ff53650c"
   },
   "outputs": [],
   "source": [
    "vocab_inp_size = dataset.num_input_tokens\n",
    "embedding_dim = 64\n",
    "units = 256\n",
    "BATCH_SIZE = dataset.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8911625-ecf9-41b6-9234-7f241a71dd4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8911625-ecf9-41b6-9234-7f241a71dd4a",
    "outputId": "6e833b6b-7b94-4132-b99a-7960817fabbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (128, 22, 256)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
    "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4cd28da3-6384-4280-9c67-9d542884f55a",
   "metadata": {
    "id": "4cd28da3-6384-4280-9c67-9d542884f55a"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "955fd636-70c1-4208-b59b-1b19d3090e50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "955fd636-70c1-4208-b59b-1b19d3090e50",
    "outputId": "0f0d3abe-695b-4104-ccaf-19e379a1c69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (128, 256)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (128, 22, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adbd8f1a-53b4-4d8d-bff6-478f2718bcd4",
   "metadata": {
    "id": "adbd8f1a-53b4-4d8d-bff6-478f2718bcd4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f7fb80f6-6d51-4b88-89aa-b10d4cbcb950",
   "metadata": {
    "id": "f7fb80f6-6d51-4b88-89aa-b10d4cbcb950"
   },
   "outputs": [],
   "source": [
    "vocab_tar_size = dataset.num_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c4dd296f-1d52-4b1a-9caa-e56ae23af6ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4dd296f-1d52-4b1a-9caa-e56ae23af6ea",
    "outputId": "e8eaaa9d-89d6-4a08-b49d-338c7c23d72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 67)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d718ae-5b4a-472f-9d62-e3b72a468217",
   "metadata": {
    "id": "51d718ae-5b4a-472f-9d62-e3b72a468217"
   },
   "source": [
    "## Optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d21003ab-70ee-455d-a0bd-4e16a87f6c70",
   "metadata": {
    "id": "d21003ab-70ee-455d-a0bd-4e16a87f6c70"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9MXMGXggqjam",
   "metadata": {
    "id": "9MXMGXggqjam"
   },
   "outputs": [],
   "source": [
    "def word_accuracy(real, pred):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e633463-5d0c-4080-9e0d-5cc8cb88a9b9",
   "metadata": {
    "id": "7e633463-5d0c-4080-9e0d-5cc8cb88a9b9"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "90973b6a-e060-4e22-94f6-2400e7d700f2",
   "metadata": {
    "id": "90973b6a-e060-4e22-94f6-2400e7d700f2"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([dataset.target_tokenizer.word_index[sos]] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df721112-cd36-4e6b-8608-3a1e06fcab84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df721112-cd36-4e6b-8608-3a1e06fcab84",
    "outputId": "f0be295c-2c75-4c88-d4a5-6de4e6646ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.4508\n",
      "Epoch 1 Batch 100 Loss 0.9377\n",
      "Epoch 1 Batch 200 Loss 0.8829\n",
      "Epoch 1 Batch 300 Loss 0.7952\n",
      "Epoch 1 Loss 0.9113\n",
      "Time taken for 1 epoch 587.46 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "steps_per_epoch = len(dataset.train.input_tensor)//BATCH_SIZE\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.train.batch.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
    "\n",
    "    print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421ac1f-81fc-4cec-9094-88b21ba143a6",
   "metadata": {
    "id": "6421ac1f-81fc-4cec-9094-88b21ba143a6"
   },
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5643c560-2f13-43ec-aba5-8fd6eb23762a",
   "metadata": {
    "id": "5643c560-2f13-43ec-aba5-8fd6eb23762a"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((dataset.max_target_seq_length, dataset.max_input_seq_length))\n",
    "\n",
    "    sentence = dataset.preprocess_word(sentence)\n",
    "\n",
    "    inputs = [dataset.input_tokenizer.word_index[i] for i in sentence]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=dataset.max_input_seq_length,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([dataset.target_tokenizer.word_index[sos]], 0)\n",
    "\n",
    "    for t in range(dataset.max_target_seq_length):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                            dec_hidden,\n",
    "                                                            enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += dataset.target_tokenizer.index_word[predicted_id]\n",
    "\n",
    "        if dataset.target_tokenizer.index_word[predicted_id] == eos:\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bba6377a-ec7d-4c48-8b40-e6e75bd64de3",
   "metadata": {
    "id": "bba6377a-ec7d-4c48-8b40-e6e75bd64de3"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    hindi_font = FontProperties(fname = 'Nirmala.ttf')\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=0)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, fontproperties=hindi_font)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    input = ''.join([ch for ch in sentence])[1:-1]\n",
    "    target = ''.join([ch for ch in predicted_sentence])[:-1]\n",
    "    plt.title(f\"Input: {input}  Prediction: {target}\", fontproperties=hindi_font, fontsize = 20)\n",
    "    plt.savefig(f\"{input}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9db2c059-3601-459b-b285-08cb6bda4f84",
   "metadata": {
    "id": "9db2c059-3601-459b-b285-08cb6bda4f84"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input:', sentence)\n",
    "    print('Predicted translation:', result)\n",
    "\n",
    "    attention_plot = attention_plot[:len(result),\n",
    "                                  :len(sentence)]\n",
    "    plot_attention(attention_plot, [i for i in sentence], [i for i in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "00985e4f-7438-416c-93b0-647556ce517b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "00985e4f-7438-416c-93b0-647556ce517b",
    "outputId": "b17f9a4a-7a05-4775-f18c-ad380b62781e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: @lol#\n",
      "Predicted translation: लिल#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-117-d5b7a9cdfa81>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=0)\n",
      "<ipython-input-117-d5b7a9cdfa81>:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, fontproperties=hindi_font)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A7n3LGKsiN8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7n3LGKsiN8e",
    "outputId": "11ecf21f-7a56-4658-f57c-d689b1883459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  6,  5, 19, 11, 19,  7, 11,  8,  1])"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = dataset.input_tokenizer.texts_to_sequences(\"shibobrota\")\n",
    "np.reshape(sequence, len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u_Y_4LsajI-B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_Y_4LsajI-B",
    "outputId": "d12ff317-4c22-4cca-ab34-27b1f66ef754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'h', 'i', 'b', 'o', 'b', 'r', 'o', 't', 'a']"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset.input_tokenizer.sequences_to_texts(sequence)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "zU-lii9njfj4",
   "metadata": {
    "id": "zU-lii9njfj4"
   },
   "outputs": [],
   "source": [
    "def save_predictions(data_frame, name):\n",
    "    accuracy_count = 0;\n",
    "    with open(name, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"INPUT\", \"PREDICTION\", \"TRUE\"])\n",
    "        for i, (inp, trg) in enumerate(zip(data_frame[1], data_frame[0])): \n",
    "            result, sentence, attention_plot = evaluate(inp)\n",
    "            writer.writerow([inp, result[:-1], trg])\n",
    "            print(inp, result[:-1], trg)\n",
    "            if result[:-1] == trg:\n",
    "                accuracy_count += 1\n",
    "            if (i+1) % 100 == 0 or i+1 == data_frame.size:\n",
    "                print(\"Accuracy\", (accuracy_count / (i+1)))\n",
    "\n",
    "    return accuracy_count/data_frame.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kkzktH4_qvaB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkzktH4_qvaB",
    "outputId": "2b53e599-55b1-4135-a3a3-547267683c53"
   },
   "outputs": [],
   "source": [
    "save_predictions(test_df, \"new_without_attn_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4l-qgeRyq0Y9",
   "metadata": {
    "id": "4l-qgeRyq0Y9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Without Attention-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
