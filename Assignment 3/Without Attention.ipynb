{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f85e9d-215f-45c6-95ad-d56e6e3d3759",
   "metadata": {
    "id": "auburn-draft"
   },
   "source": [
    "#### CS20M059 Shibobrota Das | CS20M007 Abhishek Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700a5ec-7c66-45f5-9539-a593bb36ddc6",
   "metadata": {
    "id": "great-tiffany"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b51cb32-fdbd-4f91-96ca-91ee41122b6b",
   "metadata": {
    "id": "gaKxXHmTkdRL"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a08fb4b5-e93b-4c82-bc45-e2a22a7dee95",
   "metadata": {
    "id": "xrxO62AQkoWM"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c70406c-fe4d-43f1-93a4-9dc617b301da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skilled-effort",
    "outputId": "b0039f46-48e2-4357-ff63-84e31e10ce49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.5.0\n",
      "Using tensorflow Addons: 0.13.0\n",
      "Using keras: 2.5.0\n",
      "Using pandas: 1.2.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "import wandb\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using tensorflow Addons:\",tfa.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ddf43393-e89f-46f4-a711-f2e7078e9e85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "split-cardiff",
    "outputId": "928563a1-ca11-4647-e59b-2ecd1757b9ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ieo5mk6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2ieo5mk6). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">crisp-water-211</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203\" target=\"_blank\">https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/6g6t6l2c\" target=\"_blank\">https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/6g6t6l2c</a><br/>\n",
       "                Run data is saved locally in <code>/content/drive/My Drive/A3-checkpoints/wandb/run-20210520_185916-6g6t6l2c</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(6g6t6l2c)</h1><iframe src=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/6g6t6l2c\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa6c5de0bd0>"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.init(project='Assignment 3', entity='iitm-cs6910-jan-may-2021-cs20m059-cs20m007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd226e1-96b2-4440-a310-15a8cf2f0035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_G5-UqDjYwf",
    "outputId": "e9af9df0-72ef-4334-b168-df94d0f8720e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive/DL-A3 Dataset/dakshina_dataset_v1.0/hi\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/My Drive/DL-A3 Dataset/dakshina_dataset_v1.0/hi/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c92d9-374e-4e0f-b2d1-7f17d895cc04",
   "metadata": {
    "id": "sweet-citizenship"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee85d467-1fac-40d1-a7ca-b00faf2d3d4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boolean-knock",
    "outputId": "e3bcd07b-b14f-4ad3-9479-964b98ca4997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13ae78d1-de5a-435a-8b39-088bd63f8e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awJtOAhGkDQc",
    "outputId": "6d5a2121-6e37-49a5-a43b-ca4eb46d5bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/A3-checkpoints\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/A3-checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6b5e6-844e-4fb9-9eeb-bcedd0cf6fd1",
   "metadata": {
    "id": "given-prediction"
   },
   "source": [
    "#### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefa85bd-2299-4503-8d29-458451185e8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "measured-restriction",
    "outputId": "fb1b28c1-df14-49c9-d94e-313d2b75d6af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42980</th>\n",
       "      <td>स्वरूप</td>\n",
       "      <td>swarup</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36244</th>\n",
       "      <td>वाल्मीक</td>\n",
       "      <td>valmik</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42820</th>\n",
       "      <td>स्प्रिंकलर</td>\n",
       "      <td>sprinkler</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0          1  2\n",
       "42980      स्वरूप     swarup  2\n",
       "36244     वाल्मीक     valmik  2\n",
       "42820  स्प्रिंकलर  sprinkler  3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e8bdb-9997-43b6-ba7e-e05879c1c4c0",
   "metadata": {
    "id": "furnished-check"
   },
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53abf538-55d3-46e0-9532-f0aded169217",
   "metadata": {
    "id": "standing-reducing"
   },
   "outputs": [],
   "source": [
    "sos = \"@\"\n",
    "eos = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7035ff0-c322-4ef6-98ac-eae0416ad3a7",
   "metadata": {
    "id": "common-matter"
   },
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, batch_size):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch = tf.data.Dataset.from_tensor_slices((self.input_tensor, self.target_tensor)).shuffle(len(self.input_tensor)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3cd7e2-7e30-44bb-8a27-77dbf944bea0",
   "metadata": {
    "id": "continental-transport"
   },
   "outputs": [],
   "source": [
    "class TransliterationDatatset:\n",
    "    def __init__(self, df_list, batch_size = 64):\n",
    "        \n",
    "        self.input_tokenizer = None\n",
    "        self.target_tokenizer = None\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "        self.batch_size = batch_size\n",
    "        # Load Data\n",
    "        self.load_dataset(df_list)\n",
    "        # Other parameters\n",
    "        self.num_input_tokens = len(self.input_tokenizer.index_word)+1\n",
    "        self.num_target_tokens = len(self.target_tokenizer.index_word)+1\n",
    "        self.max_input_seq_length = np.max([self.train.input_tensor.shape[1], self.val.input_tensor.shape[1], self.test.input_tensor.shape[1]])\n",
    "        self.max_target_seq_length = np.max([self.train.target_tensor.shape[1], self.val.target_tensor.shape[1], self.test.target_tensor.shape[1]])\n",
    "        \n",
    "    def preprocess_word(self, w):\n",
    "        return sos + str(w) + eos\n",
    "    \n",
    "    def create_dataset(self, data_frame):\n",
    "        input_words = []\n",
    "        target_words = []\n",
    "        # Shuffle the data_frame before creating dataset\n",
    "        df = data_frame\n",
    "        for i in range(5):\n",
    "            df = shuffle(df)\n",
    "        for x, y in zip(df[1], df[0]):\n",
    "            input_words.append(str(x))\n",
    "            target_words.append(self.preprocess_word(y))\n",
    "        return (input_words, target_words)\n",
    "    \n",
    "    def load_dataset(self, df_list):\n",
    "        # df_list should have train -> val -> test in sequence\n",
    "        \n",
    "        self.input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        self.target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        \n",
    "        ds_list = []\n",
    "        \n",
    "        for df in df_list:\n",
    "            # Get the words list\n",
    "            (input_words, target_words) = self.create_dataset(df)\n",
    "            # Fit on the set of words\n",
    "            self.input_tokenizer.fit_on_texts(input_words)\n",
    "            self.target_tokenizer.fit_on_texts(target_words)\n",
    "            ds_list.append((input_words, target_words))\n",
    "                    \n",
    "        self.target_tokenizer.index_word.update({0:\" \"})\n",
    "        self.input_tokenizer.index_word.update({0:\" \"})\n",
    "        \n",
    "        input_word_len = []\n",
    "        target_word_len = []\n",
    "        \n",
    "        tensor_list = []\n",
    "        \n",
    "        for i, (input_words, target_words) in enumerate(ds_list):\n",
    "            input_tensor = self.input_tokenizer.texts_to_sequences(input_words)\n",
    "            target_tensor = self.target_tokenizer.texts_to_sequences(target_words)\n",
    "            tensor_list.append((input_tensor, target_tensor))\n",
    "            input_word_len.append(np.max([len(x) for x in input_tensor]))\n",
    "            target_word_len.append(np.max([len(x) for x in target_tensor]))\n",
    "        \n",
    "        for i, (input_tensor, target_tensor) in enumerate(tensor_list):\n",
    "            \n",
    "            input_tensor = pad_sequences(input_tensor, padding='post', maxlen = np.max(input_word_len))\n",
    "            target_tensor = pad_sequences(target_tensor, padding='post', maxlen = np.max(target_word_len))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.train = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            elif i == 1:\n",
    "                self.val = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            else:\n",
    "                self.test = LexDataset(input_tensor, target_tensor, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b06317-dab4-4455-812e-1b34679e27b1",
   "metadata": {
    "id": "offensive-islam",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TransliterationDatatset([train_df, val_df, test_df], 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb817ef-9206-4341-807a-4b4db2113340",
   "metadata": {
    "id": "traditional-oxygen"
   },
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1da1956c-d5be-4d10-a263-f565341e5d6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soviet-speed",
    "outputId": "2c158b50-cf42-4f17-ac18-0cd7cb296d33",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44204, 20), (44204, 21))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset.train.input_tensor.shape, dataset.train.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a008930-d6da-4be0-898c-153f49b8845a",
   "metadata": {
    "id": "sorted-geneva"
   },
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3c2a7df-ec58-40b6-9ba1-6b7782fdfa0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "great-neutral",
    "outputId": "d6053b61-47cb-414d-94ee-f6ac0296af74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 20), (4358, 21))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data\n",
    "dataset.val.input_tensor.shape, dataset.val.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da416c97-6ef6-4855-8968-dfcd1fe8ff5a",
   "metadata": {
    "id": "wanted-pharmacy"
   },
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa011970-5547-4783-a89d-8ab8c3438fa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intermediate-survey",
    "outputId": "da8f3d32-f387-4087-bd94-d28b2c1bfed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4502, 20), (4502, 21))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "dataset.test.input_tensor.shape, dataset.test.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ada4f-733d-4301-93b2-1ade66cde9a8",
   "metadata": {
    "id": "great-print"
   },
   "source": [
    "#### Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bba2c1c4-7fb6-454b-8210-13398ed7406b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "affecting-toner",
    "outputId": "5d75818e-099c-460c-e598-a0176e19a5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 67)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "dataset.num_input_tokens, dataset.num_target_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a249a5-d5ea-46c6-ab4f-a7d0e08b05f3",
   "metadata": {
    "id": "french-jason"
   },
   "source": [
    "#### Maximum Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c96afcb-d6ff-4b44-89f2-5d0797709ce4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "regional-friday",
    "outputId": "916fb584-b8f1-4ea9-c98d-3bc1505194cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max seq length\n",
    "dataset.max_input_seq_length, dataset.max_target_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24fd33-e9fd-47c7-be52-62705caf2ebc",
   "metadata": {
    "id": "incredible-gallery"
   },
   "source": [
    "#### Example batch - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3c95122-8a50-482b-ae5d-994a74f31765",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "academic-exploration",
    "outputId": "f16577f2-d3f5-4e7f-81c9-c3666f256f1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 20]), TensorShape([128, 21]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset.train.batch))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81646f07-05bf-4c75-aaf4-ce964bf9e458",
   "metadata": {},
   "source": [
    "## Encoder and Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f89910-c99b-40bf-bfff-a45cb0e54472",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "310ed27c-251f-4aa2-8b48-2b3942aaf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, dataset.num_input_tokens))\n",
    "encoder_embedding = Embedding\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, dataset.num_target_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(dataset.num_target_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b873cc90-17f1-4bed-994e-fe238df4ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_count(t, val):\n",
    "    elements_equal_to_value = tf.equal(t, val)\n",
    "    as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "    count = tf.reduce_sum(as_ints)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "041844fd-53f1-4022-ae6a-448df7ac6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_accuracy(real, pred):\n",
    "    \n",
    "    pred = tf.cast(tf.argmax(pred, axis=2), tf.int32)\n",
    "    real = tf.cast(tf.argmax(real, axis=2), tf.int32)\n",
    "    correct_preds = tf.equal(pred, real)\n",
    "    row_wise = tf.reduce_mean(tf.cast(correct_preds, tf.float32), axis=1)\n",
    "    count = tf_count(row_wise, 1.0)\n",
    "    \n",
    "    return float(count)/float(len(row_wise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf757f66-30c2-49f1-a6a6-3490177d7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"nadam\", loss=\"categorical_crossentropy\", metrics=[word_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "670501b6-abd3-4742-af49-da5c7ff26945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None, 67)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1024), (None 4313088     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 1024), 4472832     input_4[0][0]                    \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 67)     68675       lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,854,595\n",
      "Trainable params: 8,854,595\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35a7c3e7-e480-47d3-a200-d455099be374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18/346 [>.............................] - ETA: 41:56 - loss: 1.9725 - word_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2b8eb3c50e55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                  dataset.num_target_tokens)\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdecoder_target_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "encoder_input_data = tf.one_hot(dataset.train.input_tensor, dataset.num_input_tokens)\n",
    "decoder_input_data = tf.one_hot(dataset.train.target_tensor, dataset.num_target_tokens)\n",
    "\n",
    "decoder_target_data = tf.one_hot(pad_sequences(dataset.train.target_tensor[:,1:], padding='post', maxlen = dataset.max_target_seq_length), \n",
    "                                 dataset.num_target_tokens)\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=dataset.batch_size,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2c233-4f9a-471a-8ff9-dfe5950a4963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8911625-ecf9-41b6-9234-7f241a71dd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd28da3-6384-4280-9c67-9d542884f55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fd636-70c1-4208-b59b-1b19d3090e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
