{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.4.1\n",
      "Using tensorflow Addons: 0.12.1\n",
      "Using keras: 2.4.0\n",
      "Using pandas: 1.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using tensorflow Addons:\",tfa.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liquid-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-spyware",
   "metadata": {},
   "source": [
    "## Load and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approved-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "backed-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, inp_word_tokenizer, targ_word_tokenizer):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.inp_word_tokenizer = inp_word_tokenizer\n",
    "        self.targ_word_tokenizer = targ_word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "joined-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(words, tokenizer):\n",
    "    tensor = tokenizer.texts_to_sequences(words)\n",
    "    \n",
    "    #Pad the smaller words\n",
    "    tensor = pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    # Return the tensor and the tokenizer\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "matched-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataframe to \n",
    "def create_dataset(data_frame):\n",
    "    input_words = []\n",
    "    target_words = []\n",
    "    for x, y in zip(data_frame[1], data_frame[0]):\n",
    "        # Add words to respective lists\n",
    "        input_words.append(\"@\"+str(x)+\"#\")\n",
    "        target_words.append(\"@\"+str(y)+\"#\")\n",
    "    return input_words, target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "terminal-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_frame_list):\n",
    "    # Initialize the tokenizer\n",
    "    input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "    target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "    \n",
    "    dataset_list = []\n",
    "    \n",
    "    for df in data_frame_list:\n",
    "        # Get the words list\n",
    "        input_words, target_words = create_dataset(df)\n",
    "        # Fit on the set of words\n",
    "        input_tokenizer.fit_on_texts(input_words)\n",
    "        target_tokenizer.fit_on_texts(target_words)\n",
    "        dataset_list.append((input_words, target_words))\n",
    "    \n",
    "    words_data = []\n",
    "    \n",
    "    target_tokenizer.index_word.update({0:\" \"})\n",
    "    input_tokenizer.index_word.update({0:\" \"})\n",
    "    \n",
    "    for (input_words, target_words) in dataset_list:\n",
    "        # Tokenize the words\n",
    "        input_tensor, inp_word_tokenizer = tokenize(input_words, input_tokenizer)\n",
    "        target_tensor, targ_word_tokenizer = tokenize(target_words, target_tokenizer)\n",
    "        words_data.append(LexDataset(input_tensor, target_tensor, inp_word_tokenizer, targ_word_tokenizer))\n",
    "\n",
    "    return words_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "olympic-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Val input tensor: (4358, 20) | Shape of Val target tensor: (4358, 16)\n",
      "Shape of Train input tensor: (44204, 22) | Shape of Train target tensor: (44204, 21)\n",
      "Shape of Test input tensor: (4502, 18) | Shape of Test target tensor: (4502, 17)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset([val_df, train_df, test_df])\n",
    "\n",
    "print(f'Shape of Val input tensor: {np.shape(dataset[0].input_tensor)} | Shape of Val target tensor: {np.shape(dataset[0].target_tensor)}')\n",
    "print(f'Shape of Train input tensor: {np.shape(dataset[1].input_tensor)} | Shape of Train target tensor: {np.shape(dataset[1].target_tensor)}')\n",
    "print(f'Shape of Test input tensor: {np.shape(dataset[2].input_tensor)} | Shape of Test target tensor: {np.shape(dataset[2].target_tensor)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(tk, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print(f'{t} ----> {tk.index_word[t]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "horizontal-hardware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Input Word; index to character mapping\n",
      "2 ----> @\n",
      "1 ----> a\n",
      "4 ----> n\n",
      "13 ----> k\n",
      "1 ----> a\n",
      "4 ----> n\n",
      "3 ----> #\n",
      "\n",
      "Val Target Word; index to character mapping\n",
      "1 ----> @\n",
      "31 ----> अ\n",
      "10 ----> ं\n",
      "8 ----> क\n",
      "6 ----> न\n",
      "2 ----> #\n"
     ]
    }
   ],
   "source": [
    "print(\"Val Input Word; index to character mapping\")\n",
    "convert(dataset[0].inp_word_tokenizer, dataset[0].input_tensor[0])\n",
    "print()\n",
    "print(\"Val Target Word; index to character mapping\")\n",
    "convert(dataset[0].targ_word_tokenizer, dataset[0].target_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attractive-issue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(dataset[0].inp_word_tokenizer.index_word)+1\n",
    "num_decoder_tokens = len(dataset[0].targ_word_tokenizer.index_word)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "close-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([np.shape(dataset[i].input_tensor)[1] for i in range(len(dataset))])\n",
    "max_decoder_seq_length = max([np.shape(dataset[i].target_tensor)[1] for i in range(len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "basic-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].targ_word_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-midwest",
   "metadata": {},
   "source": [
    "## Tensorflow Dataset from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "portable-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "embedding_dim = 16\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-decision",
   "metadata": {},
   "source": [
    "#### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "parliamentary-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dataset[1].input_tensor, dataset[1].target_tensor)).shuffle(len(dataset[1].input_tensor))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-austria",
   "metadata": {},
   "source": [
    "#### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "crucial-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((dataset[0].input_tensor, dataset[0].target_tensor)).shuffle(len(dataset[0].input_tensor))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-membership",
   "metadata": {},
   "source": [
    "#### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bottom-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((dataset[2].input_tensor, dataset[2].target_tensor)).shuffle(len(dataset[2].input_tensor))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mighty-abuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 22]), TensorShape([32, 21]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-percentage",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "simple-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, dropout=0.2, layer_type=\"GRU\", num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_units = encoder_units\n",
    "        self.batch_size = batch_size\n",
    "        self.layer_type = layer_type\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # RNN Layer(s)\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.layer = LSTM(self.encoder_units, return_state = True, return_sequences=True, dropout = dropout, name = 'LSTM_encoder_1', recurrent_initializer='glorot_uniform')\n",
    "            for i in range(num_layers - 1):\n",
    "                self.layer = LSTM(self.encoder_units, return_state = True, return_sequences=True, dropout = dropout, \n",
    "                                  name = 'LSTM_encoder_'+str(i+2), recurrent_initializer='glorot_uniform')(self.layer)\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.layer = GRU(self.encoder_units, return_state = True, return_sequences=True, dropout = dropout, name = 'GRU_encoder_1', recurrent_initializer='glorot_uniform')\n",
    "            for i in range(num_layers - 1):\n",
    "                self.layer = GRU(self.encoder_units, return_state = True, return_sequences=True, dropout = dropout, \n",
    "                                 name = 'GRU_encoder_'+str(i+2), recurrent_initializer='glorot_uniform')(self.layer)\n",
    "        else:\n",
    "            self.layer = SimpleRNN(self.encoder_units, return_state = True, return_sequences=True, dropout = dropout, name = 'SimpleRNN_encoder_1', recurrent_initializer='glorot_uniform')\n",
    "            for i in range(num_layers - 1):\n",
    "                self.layer = SimpleRNN(self.encoder_units, return_state = True, return_sequences=True, dropout = dropout, \n",
    "                                       name = 'SimpleRNN_encoder_'+str(i+2), recurrent_initializer='glorot_uniform')(self.layer)\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            output, state_h, state_c = self.layer(x, initial_state = hidden)\n",
    "            return output, state_h, state_c\n",
    "        else:\n",
    "            output, state = self.layer(x, initial_state=hidden)\n",
    "            return output, state, None\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            return [tf.zeros((self.batch_size, self.encoder_units)), tf.zeros((self.batch_size, self.encoder_units))] \n",
    "        else:\n",
    "            return tf.zeros((self.batch_size, self.encoder_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "express-seeking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (32, 22, 128)\n",
      "Encoder Hidden state shape: (batch size, units) (32, 128)\n",
      "Encoder Cell state shape: (batch size, units) (32, 128)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(num_encoder_tokens, embedding_dim, units, BATCH_SIZE, 0.2, \"LSTM\", 1)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden, sample_cell = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
    "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)\n",
    "if encoder.layer_type == \"LSTM\":\n",
    "    print('Encoder Cell state shape: (batch size, units)', sample_cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-removal",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "powerful-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size, dropout=0.2, layer_type=\"LSTM\", num_layers=1, attention_type='luong'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_units = decoder_units\n",
    "        self.batch_size = batch_size\n",
    "        self.layer_type = layer_type\n",
    "        self.num_layers = num_layers\n",
    "        self.attention_type = attention_type\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Final Dense Layer - Fully Connected: on which softmax will be applied\n",
    "        self.fc = Dense(vocab_size, activation='softmax')\n",
    "        \n",
    "        # Define the fundamental cell for decoder recurrent structure\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.decoder_rnn_cell = LSTMCell(self.decoder_units)\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.decoder_rnn_cell = GRUCell(self.decoder_units)\n",
    "        else:\n",
    "            self.decoder_rnn_cell = SimpleRNNCell(self.decoder_units)\n",
    "                    \n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        \n",
    "        # Create attention mechanism\n",
    "        self.attention_mechanism = self.build_attention_mechanism(self.decoder_units, None, self.batch_size*[max_decoder_seq_length], \n",
    "                                                                  self.attention_type)\n",
    "        \n",
    "        # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
    "        self.rnn_cell = self.build_rnn_cell()\n",
    "\n",
    "        # Define the decoder with respect to fundamental rnn cell\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def build_rnn_cell(self):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, self.attention_mechanism, attention_layer_size=self.decoder_units)\n",
    "        return rnn_cell\n",
    "\n",
    "    def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
    "        # ------------- #\n",
    "        # typ: Which sort of attention (Bahdanau, Luong)\n",
    "        # dec_units: final dimension of attention outputs \n",
    "        # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
    "        # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
    "\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state, Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_size, dtype=Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
    "        return decoder_initial_state\n",
    "\n",
    "\n",
    "    def call(self, inputs, initial_state):\n",
    "        x = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_size*[max_decoder_seq_length-1])\n",
    "        return outputs      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "mental-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Outputs Shape:  (32, 20, 67)\n"
     ]
    }
   ],
   "source": [
    "# Test decoder stack\n",
    "\n",
    "decoder = Decoder(num_decoder_tokens, embedding_dim, units, BATCH_SIZE, 0.2, \"LSTM\", 1, 'luong')\n",
    "sample_x = tf.random.uniform((BATCH_SIZE, max_decoder_seq_length))\n",
    "decoder.attention_mechanism.setup_memory(sample_output)\n",
    "if decoder.layer_type == \"LSTM\":\n",
    "    initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_hidden, sample_cell], tf.float32)\n",
    "else:\n",
    "    initial_state = decoder.build_initial_state(BATCH_SIZE, sample_hidden, tf.float32)\n",
    "\n",
    "\n",
    "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-width",
   "metadata": {},
   "source": [
    "## Optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "reasonable-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, target_vocab_size )\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-constraint",
   "metadata": {},
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "floppy-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-weekend",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "technological-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "\n",
    "    dec_input = targ[ : , :-1 ] # Ignore <end> token\n",
    "    real = targ[ : , 1: ]         # ignore <start> token\n",
    "\n",
    "    # Set the AttentionMechanism object with encoder_outputs\n",
    "    decoder.attention_mechanism.setup_memory(enc_output)\n",
    "\n",
    "    # Create AttentionWrapperState as initial_state for decoder\n",
    "    if decoder.layer_type == \"LSTM\":\n",
    "        decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "    else:\n",
    "        decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, enc_h, tf.float32)\n",
    "        \n",
    "    pred = decoder(dec_input, decoder_initial_state)\n",
    "    logits = pred.rnn_output\n",
    "    loss = loss_function(real, logits)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-clearance",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "defined-creation",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 22) (32, 21)\n",
      "tf.Tensor(\n",
      "[[ 2  9 24 10 10 13  1  1  7 18  1  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 14 10 10 14  1 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 23  1 26 19  1  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  9  6  1 14 14 18 22  5 13  5  8  9  1  3  0  0  0  0  0  0  0]\n",
      " [ 2 23 10  9  5  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 17  1  7  5  8  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 22  6  6  1  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  9  9 10  9  9 16 10  4  8  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 19  1  1 14 20 10 10  7  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  9  6  7 10  9  6  8  6  8  1  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 23 15 17  5  8 10  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  9  6  1  7 16  4  1  1 13  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 24 10  9  8 14  1  4 12  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 14 15 22 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  6  1  7  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 16 11  8 24  1  4  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 24 11  7 13  9  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 22  6  1  5  8  1  4 18  1  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 17  7  1  8  5 19  1  4 12  6  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 23  6  1 12  8 10  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  1 20 10  6  1 14  4  1  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  9  5  4 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21  1  4 20  1  4  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  1 19  6  5 20  1  1 12  1  4  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 19  1 14 14 10 19  1 23  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 17  7  1 18  1 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 13 15  4 24  1  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 16  7  5  4  1 14  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 17  1  9  6  8 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 16  1 12  6 18 16 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 14  5 13  6  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 16  1  4 12  5  7 11  4  3  0  0  0  0  0  0  0  0  0  0  0  0]], shape=(32, 22), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  9  5 16 12  8  3  4  5 19  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 13 12 13  3 51 10  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 21 21  5 25  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 27 13  5 19 30  7  8  7 11  5  9  3  2  0  0  0  0  0  0  0]\n",
      " [ 1 21 14  9  7 19  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 17  3  4  7 11  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 47  3  6  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 31  9 14  9 15 14 10 23  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 25  3 13 16 12  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 27  5  4 14 38  5 50 11  3  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 21 24 17  7 23  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 27  4  5 15  6  3  8  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 16 14  9  5 23 13 36 10 28  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 13 24  9 12  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 26  4 12  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 15 18 23 16  3  6 12  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 16  4  5  8  5  9  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 30 36 11  6  5 19  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 17  5  4 11  7 25 10 32  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 54 28 33 11 14  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 31 16 14 26 13  6  3  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  9 12 10 22  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 22 10 16  3  6 12  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 31 34  7 16  3 20  6  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 25 13  5 13 14 25  3 21  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 17  5  4 19  3 22  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  8 24 10 31  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 15 49 41  3 13  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 17 27  5 11 18  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 15  3 32  5 19 15 18 10  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 13  7 39  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 15 10 20  7  4 18 10  2  0  0  0  0  0  0  0  0  0  0  0  0]], shape=(32, 21), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-25-d02f339dd27e>:27 train_step  *\n        optimizer.apply_gradients(zip(gradients, variables))\n    c:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:598 apply_gradients  **\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    c:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:78 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['encoder/embedding/embeddings:0', 'encoder/LSTM_encoder_1/lstm_cell/kernel:0', 'encoder/LSTM_encoder_1/lstm_cell/recurrent_kernel:0', 'encoder/LSTM_encoder_1/lstm_cell/bias:0', 'decoder_2/embedding_3/embeddings:0', 'decoder_2/basic_decoder_2/decoder/dense_2/kernel:0', 'decoder_2/basic_decoder_2/decoder/dense_2/bias:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/lstm_cell_3/kernel:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/lstm_cell_3/recurrent_kernel:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/lstm_cell_3/bias:0', 'LuongAttention/memory_layer/kernel:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/attention_layer/kernel:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d95c6faf3b40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-25-d02f339dd27e>:27 train_step  *\n        optimizer.apply_gradients(zip(gradients, variables))\n    c:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:598 apply_gradients  **\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    c:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:78 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['encoder/embedding/embeddings:0', 'encoder/LSTM_encoder_1/lstm_cell/kernel:0', 'encoder/LSTM_encoder_1/lstm_cell/recurrent_kernel:0', 'encoder/LSTM_encoder_1/lstm_cell/bias:0', 'decoder_2/embedding_3/embeddings:0', 'decoder_2/basic_decoder_2/decoder/dense_2/kernel:0', 'decoder_2/basic_decoder_2/decoder/dense_2/bias:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/lstm_cell_3/kernel:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/lstm_cell_3/recurrent_kernel:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/lstm_cell_3/bias:0', 'LuongAttention/memory_layer/kernel:0', 'decoder_2/basic_decoder_2/decoder/attention_wrapper_2/attention_layer/kernel:0'].\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "steps_per_epoch = np.shape(dataset[1].input_tensor)[0] // BATCH_SIZE\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-dressing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-mauritius",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
