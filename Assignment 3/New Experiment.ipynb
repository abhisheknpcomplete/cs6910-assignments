{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electronic-press",
   "metadata": {},
   "source": [
    "#### CS20M059 Shibobrota Das | CS20M007 Abhishek Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-telescope",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separate-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.4.1\n",
      "Using tensorflow Addons: 0.12.1\n",
      "Using keras: 2.4.0\n",
      "Using pandas: 1.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "import os\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using tensorflow Addons:\",tfa.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-twins",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-gnome",
   "metadata": {},
   "source": [
    "#### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generous-metadata",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>वॉयस</td>\n",
       "      <td>voice</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>जनगण</td>\n",
       "      <td>jangan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>कीकर</td>\n",
       "      <td>kicker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1  2\n",
       "3706  वॉयस   voice  6\n",
       "1281  जनगण  jangan  2\n",
       "750   कीकर  kicker  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-outside",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expensive-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = \"@\"\n",
    "eos = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "international-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, batch_size):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch = tf.data.Dataset.from_tensor_slices((self.input_tensor, self.target_tensor)).shuffle(len(self.input_tensor)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "orange-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransliterationDatatset:\n",
    "    def __init__(self, df_list, problem_type = \"en-hi\", batch_size = 32):\n",
    "        self.problem_type = problem_type\n",
    "        self.input_tokenizer = None\n",
    "        self.target_tokenizer = None\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "        self.batch_size = batch_size\n",
    "        # Load Data\n",
    "        self.load_dataset(df_list)\n",
    "        \n",
    "    def preprocess_word(self, w):\n",
    "        return sos + str(w) + eos\n",
    "    \n",
    "    def create_dataset(self, data_frame):\n",
    "        input_words = []\n",
    "        target_words = []\n",
    "        # Shuffle the data_frame before creating dataset\n",
    "        df_shuffled = shuffle(data_frame)\n",
    "        for x, y in zip(df_shuffled[1], df_shuffled[0]):\n",
    "            input_words.append(self.preprocess_word(x))\n",
    "            target_words.append(self.preprocess_word(y))\n",
    "        return (input_words, target_words)\n",
    "    \n",
    "    def load_dataset(self, df_list):\n",
    "        # df_list should have train -> val -> test in sequence\n",
    "        \n",
    "        self.input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        self.target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        \n",
    "        ds_list = []\n",
    "        \n",
    "        for df in df_list:\n",
    "            # Get the words list\n",
    "            (input_words, target_words) = self.create_dataset(df)\n",
    "            # Fit on the set of words\n",
    "            self.input_tokenizer.fit_on_texts(input_words)\n",
    "            self.target_tokenizer.fit_on_texts(target_words)\n",
    "            ds_list.append((input_words, target_words))\n",
    "                    \n",
    "        self.target_tokenizer.index_word.update({0:\" \"})\n",
    "        self.input_tokenizer.index_word.update({0:\" \"})\n",
    "        \n",
    "        for i, (input_words, target_words) in enumerate(ds_list):\n",
    "            \n",
    "            input_tensor = self.input_tokenizer.texts_to_sequences(input_words)\n",
    "            input_tensor = pad_sequences(input_tensor, padding='post')\n",
    "            \n",
    "            target_tensor = self.target_tokenizer.texts_to_sequences(target_words)\n",
    "            target_tensor = pad_sequences(target_tensor, padding='post')\n",
    "            \n",
    "            if i == 0:\n",
    "                self.train = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            elif i == 1:\n",
    "                self.val = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            else:\n",
    "                self.test = LexDataset(input_tensor, target_tensor, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "olive-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TransliterationDatatset([train_df, val_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-press",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "urban-container",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44204, 22), (44204, 21))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset.train.input_tensor.shape, dataset.train.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-auditor",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "urban-legend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 20), (4358, 16))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data\n",
    "dataset.val.input_tensor.shape, dataset.val.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-architect",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tested-roller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4502, 18), (4502, 17))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "dataset.test.input_tensor.shape, dataset.test.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-finland",
   "metadata": {},
   "source": [
    "#### Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dried-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "num_encoder_tokens = len(dataset.input_tokenizer.index_word)+1\n",
    "num_decoder_tokens = len(dataset.target_tokenizer.index_word)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-stupid",
   "metadata": {},
   "source": [
    "#### Maximum Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tested-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max seq length\n",
    "max_encoder_seq_length = np.max([dataset.train.input_tensor.shape[1], dataset.val.input_tensor.shape[1], dataset.test.input_tensor.shape[1]])\n",
    "max_decoder_seq_length = np.max([dataset.train.target_tensor.shape[1], dataset.val.target_tensor.shape[1], dataset.test.target_tensor.shape[1]])\n",
    "max_encoder_seq_length, max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-ordering",
   "metadata": {},
   "source": [
    "#### Example batch - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crucial-payment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 22]), TensorShape([32, 21]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset.train.batch))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-driving",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "connected-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, layer_type = \"SimpleRNN\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        self.layer_type = layer_type\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        ##-------- RNN layer in Encoder ------- ##\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.layer = LSTM(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.layer = GRU(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        else:\n",
    "            self.layer = SimpleRNN(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "\n",
    "    def call(self, inputs, hidden):\n",
    "        inputs = self.embedding(inputs)\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            output, h, c = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, c\n",
    "        else:\n",
    "            output, h = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, None\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            return [tf.zeros((self.batch_size, self.encoder_units)), tf.zeros((self.batch_size, self.encoder_units))]\n",
    "        else:\n",
    "            return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-rates",
   "metadata": {},
   "source": [
    "#### Test Encoder Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "level-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test Encoder Stack\n",
    "\n",
    "# encoder = Encoder(num_encoder_tokens, embedding_dim, units, dataset.batch_size, \"SimpleRNN\")\n",
    "\n",
    "\n",
    "# # sample input\n",
    "# sample_hidden = encoder.initialize_hidden_state()\n",
    "# sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "# print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "# if encoder.layer_type == \"LSTM\":\n",
    "#     print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-currency",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attempted-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size, layer_type, attention_type='luong'):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.decoder_units = decoder_units\n",
    "        self.layer_type = layer_type\n",
    "        self.attention_type = attention_type\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Final Dense layer on which softmax will be applied\n",
    "        self.fc = Dense(vocab_size)\n",
    "        \n",
    "        # fundamental cell for decoder recurrent structure\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.decoder_rnn_cell = LSTMCell(self.decoder_units)\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.decoder_rnn_cell = GRUCell(self.decoder_units)\n",
    "        else:\n",
    "            self.decoder_rnn_cell = SimpleRNNCell(self.decoder_units)\n",
    "\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention = self.build_attention_mechanism(self.decoder_units, \n",
    "                                                        None, self.batch_size*[max_decoder_seq_length], \n",
    "                                                        self.attention_type)\n",
    "\n",
    "        # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
    "        self.rnn_cell = self.build_rnn_cell()\n",
    "\n",
    "        # Define the decoder with respect to fundamental rnn cell\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
    "\n",
    "        \n",
    "    def build_rnn_cell(self):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell,\n",
    "                                               self.attention,\n",
    "                                               attention_layer_size = self.decoder_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_attention_mechanism(self, decoder_units, memory, \n",
    "                                  memory_sequence_length, attention_type='luong'):\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=decoder_units, memory = memory, memory_sequence_length = memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=decoder_units, memory = memory, memory_sequence_length = memory_sequence_length)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state, Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = self.batch_size, dtype = Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state = encoder_state)\n",
    "        return decoder_initial_state\n",
    "    \n",
    "    def call(self, inputs, initial_state):\n",
    "        inputs = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(inputs, initial_state = initial_state, sequence_length = self.batch_size*[max_decoder_seq_length-1])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-grass",
   "metadata": {},
   "source": [
    "#### Test decoder stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "signal-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test decoder stack\n",
    "\n",
    "# decoder = Decoder(num_decoder_tokens, embedding_dim, units, dataset.batch_size, \"SimpleRNN\", 'luong')\n",
    "# sample_x = tf.random.uniform((dataset.batch_size, max_decoder_seq_length))\n",
    "# decoder.attention.setup_memory(sample_output)\n",
    "# if decoder.layer_type == \"LSTM\":\n",
    "#     initial_state = decoder.build_initial_state(dataset.batch_size, [sample_h, sample_c], tf.float32)\n",
    "# else:\n",
    "#     initial_state = decoder.build_initial_state(dataset.batch_size, sample_h, tf.float32)\n",
    "\n",
    "\n",
    "# sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "# print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-denver",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "becoming-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"layer_type\": \"LSTM\",\n",
    "    \"units\": 128,\n",
    "    \"embedding_dim\": 16,\n",
    "    \"optimiser\": \"nadam\",\n",
    "    \"num_encoders\": 1,\n",
    "    \"num_decoders\": 1,\n",
    "    \"dropout\": 0.2,\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": dataset.batch_size,\n",
    "    \"attention\": \"luong\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-doctrine",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "moving-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-sympathy",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fitted-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    cross_entropy = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-demonstration",
   "metadata": {},
   "source": [
    "#### Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "plastic-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nuclear-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0.0 Loss 1.5241\n",
      "Epoch 1 Batch 1.0 Loss 0.9789\n",
      "Epoch 1 Batch 2.0 Loss 0.9556\n",
      "Epoch 1 Batch 3.0 Loss 0.7652\n",
      "Epoch 1 Batch 4.0 Loss 0.5434\n",
      "Epoch 1 Batch 5.0 Loss 0.4497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-3e69284998e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_ExpandDimsGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ExpandDims\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_ExpandDimsGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_ReshapeToInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_ReshapeToInput\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    791\u001b[0m   \u001b[1;34m\"\"\"Reshapes the gradient to the shape of the original input.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m   return array_ops.reshape(\n\u001b[1;32m--> 793\u001b[1;33m       _IndexedSlicesToTensorNoWarning(grad), array_ops.shape(op.inputs[0]))\n\u001b[0m\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m   \"\"\"\n\u001b[1;32m--> 649\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibo\\.pyenv\\pyenv-win\\versions\\3.8.8\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   9154\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9155\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9156\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   9157\u001b[0m         _ctx, \"Shape\", name, input, \"out_type\", out_type)\n\u001b[0;32m   9158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Encoder\n",
    "encoder = Encoder(num_encoder_tokens, config[\"embedding_dim\"], \n",
    "                  config[\"units\"], config[\"batch_size\"], \n",
    "                  config[\"layer_type\"])\n",
    "\n",
    "## Decoder\n",
    "decoder = Decoder(num_decoder_tokens, config[\"embedding_dim\"], \n",
    "                  config[\"units\"], config[\"batch_size\"], \n",
    "                  config[\"layer_type\"], config[\"attention\"])\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = config[\"batch_size\"]\n",
    "steps_per_epoch = int(np.shape(dataset.train.input_tensor)[0]//dataset.batch_size)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    dataset.train.batch.shuffle(BATCH_SIZE)\n",
    "    \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.train.batch.take(steps_per_epoch)):        \n",
    "        batch_loss = 0\n",
    "\n",
    "        with GradientTape() as tape:\n",
    "            enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "\n",
    "            dec_input = targ[ : , :-1 ]       # Ignore '#' token\n",
    "            real = targ[ : , 1: ]             # ignore '@' token\n",
    "\n",
    "            # Set the AttentionMechanism object with encoder_outputs\n",
    "            decoder.attention.setup_memory(enc_output)\n",
    "\n",
    "            # Create AttentionWrapperState as initial_state for decoder\n",
    "            if decoder.layer_type == \"LSTM\":\n",
    "                decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "            else:\n",
    "                decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, enc_h, tf.float32)\n",
    "            pred = decoder(dec_input, decoder_initial_state)\n",
    "            logits = pred.rnn_output\n",
    "            batch_loss = loss_function(real, logits)\n",
    "\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        gradients = tape.gradient(batch_loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch/100,\n",
    "                                                   batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print(f'Epoch {epoch + 1} Loss {(total_loss / steps_per_epoch):.4f}')\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-realtor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-routine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
