{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "matched-blast",
   "metadata": {},
   "source": [
    "#### CS20M059 Shibobrota Das | CS20M007 Abhishek Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-cross",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mediterranean-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.4.1\n",
      "Using tensorflow Addons: 0.12.1\n",
      "Using keras: 2.4.0\n",
      "Using pandas: 1.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using tensorflow Addons:\",tfa.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-candidate",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compressed-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-wealth",
   "metadata": {},
   "source": [
    "#### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-calibration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>दालों</td>\n",
       "      <td>dalo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>अर्थतंत्र</td>\n",
       "      <td>arthtantra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>एस्थेटिक्स</td>\n",
       "      <td>asthetics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1  2\n",
       "1873       दालों        dalo  1\n",
       "143    अर्थतंत्र  arthtantra  1\n",
       "554   एस्थेटिक्स   asthetics  2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-circular",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "three-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = \"@\"\n",
    "eos = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applied-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, batch_size):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch = tf.data.Dataset.from_tensor_slices((self.input_tensor, self.target_tensor)).shuffle(len(self.input_tensor)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "underlying-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransliterationDatatset:\n",
    "    def __init__(self, df_list, problem_type = \"en-hi\", batch_size = 250):\n",
    "        self.problem_type = problem_type\n",
    "        self.input_tokenizer = None\n",
    "        self.target_tokenizer = None\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "        self.batch_size = batch_size\n",
    "        # Load Data\n",
    "        self.load_dataset(df_list)\n",
    "        \n",
    "    def preprocess_word(self, w):\n",
    "        return sos + str(w) + eos\n",
    "    \n",
    "    def create_dataset(self, data_frame):\n",
    "        input_words = []\n",
    "        target_words = []\n",
    "        # Shuffle the data_frame before creating dataset\n",
    "        df_shuffled = shuffle(data_frame)\n",
    "        for x, y in zip(df_shuffled[1], df_shuffled[0]):\n",
    "            input_words.append(self.preprocess_word(x))\n",
    "            target_words.append(self.preprocess_word(y))\n",
    "        return (input_words, target_words)\n",
    "    \n",
    "    def load_dataset(self, df_list):\n",
    "        # df_list should have train -> val -> test in sequence\n",
    "        \n",
    "        self.input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        self.target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        \n",
    "        ds_list = []\n",
    "        \n",
    "        for df in df_list:\n",
    "            # Get the words list\n",
    "            (input_words, target_words) = self.create_dataset(df)\n",
    "            # Fit on the set of words\n",
    "            self.input_tokenizer.fit_on_texts(input_words)\n",
    "            self.target_tokenizer.fit_on_texts(target_words)\n",
    "            ds_list.append((input_words, target_words))\n",
    "                    \n",
    "        self.target_tokenizer.index_word.update({0:\" \"})\n",
    "        self.input_tokenizer.index_word.update({0:\" \"})\n",
    "        \n",
    "        input_word_len = []\n",
    "        target_word_len = []\n",
    "        \n",
    "        tensor_list = []\n",
    "        \n",
    "        for i, (input_words, target_words) in enumerate(ds_list):\n",
    "            input_tensor = self.input_tokenizer.texts_to_sequences(input_words)\n",
    "            target_tensor = self.target_tokenizer.texts_to_sequences(target_words)\n",
    "            tensor_list.append((input_tensor, target_tensor))\n",
    "            input_word_len.append(np.max([len(x) for x in input_tensor]))\n",
    "            target_word_len.append(np.max([len(x) for x in target_tensor]))\n",
    "        \n",
    "        for i, (input_tensor, target_tensor) in enumerate(tensor_list):\n",
    "            \n",
    "            input_tensor = pad_sequences(input_tensor, padding='post', maxlen = np.max(input_word_len))\n",
    "            target_tensor = pad_sequences(target_tensor, padding='post', maxlen = np.max(target_word_len))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.train = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            elif i == 1:\n",
    "                self.val = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            else:\n",
    "                self.test = LexDataset(input_tensor, target_tensor, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "composed-modem",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TransliterationDatatset([train_df, val_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-license",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "front-davis",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44204, 22), (44204, 21))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset.train.input_tensor.shape, dataset.train.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-acceptance",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impressed-button",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 22), (4358, 21))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data\n",
    "dataset.val.input_tensor.shape, dataset.val.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-resident",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-toner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4502, 22), (4502, 21))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "dataset.test.input_tensor.shape, dataset.test.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-script",
   "metadata": {},
   "source": [
    "#### Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "streaming-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "num_encoder_tokens = len(dataset.input_tokenizer.index_word)+1\n",
    "num_decoder_tokens = len(dataset.target_tokenizer.index_word)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-saudi",
   "metadata": {},
   "source": [
    "#### Maximum Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "special-shooting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max seq length\n",
    "max_encoder_seq_length = np.max([dataset.train.input_tensor.shape[1], dataset.val.input_tensor.shape[1], dataset.test.input_tensor.shape[1]])\n",
    "max_decoder_seq_length = np.max([dataset.train.target_tensor.shape[1], dataset.val.target_tensor.shape[1], dataset.test.target_tensor.shape[1]])\n",
    "max_encoder_seq_length, max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-thomas",
   "metadata": {},
   "source": [
    "#### Example batch - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "empty-national",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([250, 22]), TensorShape([250, 21]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset.train.batch))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-killer",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "passing-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, layer_type = \"SimpleRNN\", dropout = 0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        self.layer_type = layer_type\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        ##-------- RNN layer in Encoder ------- ##\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.layer = LSTM(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "            \n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.layer = GRU(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "           \n",
    "        else:\n",
    "            self.layer = SimpleRNN(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "            \n",
    "            \n",
    "    def call(self, inputs, hidden):\n",
    "        inputs = self.embedding(inputs)\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            output, h, c = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, c\n",
    "        else:\n",
    "            output, h = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, None\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            return [tf.zeros((self.batch_size, self.encoder_units)), tf.zeros((self.batch_size, self.encoder_units))]\n",
    "        else:\n",
    "            return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-evening",
   "metadata": {},
   "source": [
    "#### Test Encoder Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "authorized-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test Encoder Stack\n",
    "\n",
    "# encoder = Encoder(num_encoder_tokens, 16, 128, dataset.batch_size, \"SimpleRNN\", 3)\n",
    "\n",
    "\n",
    "# # sample input\n",
    "# sample_hidden = encoder.initialize_hidden_state()\n",
    "# sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "# print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "# if encoder.layer_type == \"LSTM\":\n",
    "#     print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-communist",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "micro-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size, layer_type, attention_type='luong'):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.decoder_units = decoder_units\n",
    "        self.layer_type = layer_type\n",
    "        self.attention_type = attention_type\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Final Dense layer on which softmax will be applied\n",
    "        self.fc = Dense(vocab_size)\n",
    "        \n",
    "        # fundamental cell for decoder recurrent structure\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.decoder_rnn_cell = LSTMCell(self.decoder_units)\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.decoder_rnn_cell = GRUCell(self.decoder_units)\n",
    "        else:\n",
    "            self.decoder_rnn_cell = SimpleRNNCell(self.decoder_units)\n",
    "\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention = self.build_attention_mechanism(self.decoder_units, \n",
    "                                                        None, self.batch_size*[max_decoder_seq_length], \n",
    "                                                        self.attention_type)\n",
    "\n",
    "        # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
    "        self.rnn_cell = self.build_rnn_cell()\n",
    "\n",
    "        # Define the decoder with respect to fundamental rnn cell\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
    "\n",
    "        \n",
    "    def build_rnn_cell(self):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell,\n",
    "                                               self.attention,\n",
    "                                               attention_layer_size = self.decoder_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_attention_mechanism(self, decoder_units, memory, \n",
    "                                  memory_sequence_length, attention_type='luong'):\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=decoder_units, memory = memory, memory_sequence_length = memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=decoder_units, memory = memory, memory_sequence_length = memory_sequence_length)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state, Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, dtype = Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state = encoder_state)\n",
    "        return decoder_initial_state\n",
    "    \n",
    "    def call(self, inputs, initial_state):\n",
    "        inputs = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(inputs, initial_state = initial_state, sequence_length = self.batch_size*[max_decoder_seq_length-1])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-lying",
   "metadata": {},
   "source": [
    "#### Test decoder stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "false-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test decoder stack\n",
    "\n",
    "# decoder = Decoder(num_decoder_tokens, embedding_dim, units, dataset.batch_size, \"SimpleRNN\", 'luong')\n",
    "# sample_x = tf.random.uniform((dataset.batch_size, max_decoder_seq_length))\n",
    "# decoder.attention.setup_memory(sample_output)\n",
    "# if decoder.layer_type == \"LSTM\":\n",
    "#     initial_state = decoder.build_initial_state(dataset.batch_size, [sample_h, sample_c], tf.float32)\n",
    "# else:\n",
    "#     initial_state = decoder.build_initial_state(dataset.batch_size, sample_h, tf.float32)\n",
    "\n",
    "\n",
    "# sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "# print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-franchise",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "express-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"layer_type\": \"GRU\",\n",
    "    \"units\": 1024,\n",
    "    \"embedding_dim\": 64,\n",
    "    \"optimiser\": \"nadam\",\n",
    "    \"num_encoders\": 1,\n",
    "    \"num_decoders\": 1,\n",
    "    \"epochs\": 100,\n",
    "    \"dropout\": 0.002,\n",
    "    \"batch_size\": dataset.batch_size,\n",
    "    \"attention\": \"luong\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-representation",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "centered-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    cross_entropy = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-virtue",
   "metadata": {},
   "source": [
    "#### Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "every-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    predictions = tf.cast(tf.argmax(pred, axis=2), tf.int32)\n",
    "    correct_preds = tf.equal(predictions, real)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-grounds",
   "metadata": {},
   "source": [
    "#### Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "authorized-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitting-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printf(data):\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.write(data)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-gregory",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "upper-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_dataset, val_dataset):\n",
    "    ## Encoder\n",
    "    encoder = Encoder(num_encoder_tokens, config[\"embedding_dim\"], \n",
    "                      config[\"units\"], config[\"batch_size\"], \n",
    "                      config[\"layer_type\"], config[\"dropout\"])\n",
    "\n",
    "    ## Decoder\n",
    "    decoder = Decoder(num_decoder_tokens, config[\"embedding_dim\"], \n",
    "                      config[\"units\"], config[\"batch_size\"], \n",
    "                      config[\"layer_type\"], config[\"attention\"])\n",
    "    \n",
    "    ## Optimizer\n",
    "    optimizer = keras.optimizers.Nadam()\n",
    "\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                     encoder=encoder,\n",
    "                                     decoder=decoder)\n",
    "\n",
    "    EPOCHS = config[\"epochs\"]\n",
    "    BATCH_SIZE = config[\"batch_size\"]\n",
    "    steps_per_epoch = np.shape(dataset.train.input_tensor)[0]//dataset.batch_size\n",
    "    val_steps_per_epoch = np.shape(val_dataset.input_tensor)[0]//dataset.batch_size\n",
    "\n",
    "    # WandB init\n",
    "    \n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "\n",
    "        train_dataset.batch.shuffle(BATCH_SIZE)\n",
    "        val_dataset.batch.shuffle(BATCH_SIZE)\n",
    "\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        val_total_loss = 0\n",
    "        val_total_accuracy = 0\n",
    "        \n",
    "        # Training Loop\n",
    "        for (batch, (inp, targ)) in enumerate(train_dataset.batch.take(steps_per_epoch)):        \n",
    "            batch_loss = 0\n",
    "            accuracy = 0\n",
    "            with GradientTape() as tape:\n",
    "                enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "                dec_input = targ[ : , :-1 ]       # Ignore '#' token\n",
    "                real = targ[ : , 1: ]             # ignore '@' token\n",
    "\n",
    "                # Set the AttentionMechanism object with encoder_outputs\n",
    "                decoder.attention.setup_memory(enc_output)\n",
    "\n",
    "                # Create AttentionWrapperState as initial_state for decoder\n",
    "                if decoder.layer_type == \"LSTM\":\n",
    "                    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "                else:\n",
    "                    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, enc_h, tf.float32)\n",
    "                \n",
    "                pred = decoder(dec_input, decoder_initial_state)\n",
    "                logits = pred.rnn_output\n",
    "                batch_loss = loss_function(real, logits)\n",
    "\n",
    "                # Experiment for Accuracy\n",
    "                accuracy = calc_accuracy(real, logits)\n",
    "\n",
    "\n",
    "            variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "            gradients = tape.gradient(batch_loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "            total_loss += batch_loss\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "            printf(f\"Training: {(100 * batch / len(dataset.train.batch.take(steps_per_epoch))):.2f}% Accuracy: {(total_accuracy / batch):.4f} Loss: {(total_loss / batch):.4f}\")\n",
    "        \n",
    "        printf(\"\\n\")\n",
    "        \n",
    "        # Validation Loop\n",
    "        for (val_batch, (inp, targ)) in enumerate(val_dataset.batch.take(steps_per_epoch)):        \n",
    "            val_batch_loss = 0\n",
    "            val_accuracy = 0\n",
    "            \n",
    "            enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "            dec_input = targ[ : , :-1 ]       # Ignore '#' token\n",
    "            real = targ[ : , 1: ]             # ignore '@' token\n",
    "\n",
    "            # Set the AttentionMechanism object with encoder_outputs\n",
    "            decoder.attention.setup_memory(enc_output)\n",
    "\n",
    "            # Create AttentionWrapperState as initial_state for decoder\n",
    "            if decoder.layer_type == \"LSTM\":\n",
    "                decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "            else:\n",
    "                decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, enc_h, tf.float32)\n",
    "\n",
    "            pred = decoder(dec_input, decoder_initial_state)\n",
    "            logits = pred.rnn_output\n",
    "            \n",
    "            val_batch_loss = loss_function(real, logits)\n",
    "            val_accuracy = calc_accuracy(real, logits)\n",
    "            \n",
    "            val_total_loss += val_batch_loss\n",
    "            val_total_accuracy += val_accuracy\n",
    "            \n",
    "            printf(f\"Validating: {(100 * val_batch / len(val_dataset.batch.take(val_steps_per_epoch))):.2f}% Accuracy: {(val_total_accuracy / val_batch):.4f} Loss: {(val_total_loss / val_batch):.4f}\")\n",
    "        \n",
    "        printf(\"\\n\")\n",
    "        # saving (checkpoint) the model every epochs\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print(f'Loss {(total_loss / steps_per_epoch):.4f} Accuracy {(total_accuracy / steps_per_epoch):.4f}')\n",
    "        print(f'Val Loss {(val_total_loss / val_steps_per_epoch):.4f} Val Accuracy {(val_total_accuracy / val_steps_per_epoch):.4f}')\n",
    "        print(f'Time taken for this epoch {(time.time() - start):.4f} sec\\n')\n",
    "        \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-harvard",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder, decoder = train_model(default_config, dataset.train, dataset.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-alabama",
   "metadata": {},
   "source": [
    "### Evaluate Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_word(word, encoder, decoder, config):\n",
    "    word = dataset.preprocess_word(word)\n",
    "\n",
    "    inputs = [dataset.input_tokenizer.word_index[i] for i in word]\n",
    "    inputs = keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen=max_encoder_seq_length,\n",
    "                                                          padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    result = ''\n",
    "\n",
    "    if encoder.layer_type == \"LSTM\":\n",
    "        enc_start_state = [tf.zeros((inference_batch_size, config[\"units\"])), tf.zeros((inference_batch_size, config[\"units\"]))]\n",
    "    else:\n",
    "        enc_start_state = tf.zeros((inference_batch_size, config[\"units\"]))\n",
    "    \n",
    "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
    "\n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "\n",
    "    start_tokens = tf.fill([inference_batch_size], dataset.target_tokenizer.word_index['@'])\n",
    "    end_token = dataset.target_tokenizer.word_index['#']\n",
    "\n",
    "    greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "\n",
    "    # Instantiate BasicDecoder object\n",
    "    decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n",
    "    # Setup Memory in decoder stack\n",
    "    decoder.attention.setup_memory(enc_out)\n",
    "\n",
    "    # set decoder_initial_state\n",
    "    if decoder.layer_type == \"LSTM\":\n",
    "        decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
    "    else:\n",
    "        decoder_initial_state = decoder.build_initial_state(inference_batch_size, enc_h, tf.float32)\n",
    "\n",
    "\n",
    "    ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \n",
    "    ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \n",
    "    ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\n",
    "\n",
    "    decoder_embedding_matrix = decoder.embedding.variables[0]\n",
    "\n",
    "    outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state = decoder_initial_state)\n",
    "    return outputs.sample_id.numpy()\n",
    "\n",
    "def transliterate(word, encoder, decoder, config):\n",
    "    result = evaluate_word(word, encoder, decoder, config)\n",
    "    print(result)\n",
    "    result = dataset.target_tokenizer.sequences_to_texts(result)\n",
    "    print(f'Input: {word}')  \n",
    "    print(f'Predicted translation: {\"\".join(result[0].split(\" \")).replace(\"#\", \"\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "transliterate(\"hello\", encoder, decoder, default_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-register",
   "metadata": {},
   "source": [
    "### BeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-engineering",
   "metadata": {
    "id": "AJ-RTQ0hsJNL"
   },
   "outputs": [],
   "source": [
    "def beam_evaluate_word(word, encoder, decoder, config, beam_width=3):\n",
    "    word = dataset.preprocess_word(word)\n",
    "\n",
    "    inputs = [dataset.input_tokenizer.word_index[i] for i in word]\n",
    "    inputs = keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen=max_encoder_seq_length,\n",
    "                                                          padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    result = ''\n",
    "\n",
    "    if encoder.layer_type == \"LSTM\":\n",
    "        enc_start_state = [tf.zeros((inference_batch_size, config[\"units\"])), tf.zeros((inference_batch_size, config[\"units\"]))]\n",
    "    else:\n",
    "        enc_start_state = tf.zeros((inference_batch_size, config[\"units\"]))\n",
    "    \n",
    "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
    "\n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "\n",
    "    start_tokens = tf.fill([inference_batch_size], dataset.target_tokenizer.word_index['@'])\n",
    "    end_token = dataset.target_tokenizer.word_index['#']\n",
    "\n",
    "\n",
    "    # From official documentation\n",
    "    # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
    "    # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
    "    # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
    "    # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
    "\n",
    "    enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n",
    "    decoder.attention.setup_memory(enc_out)\n",
    "\n",
    "    # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
    "    if decoder.layer_type == \"LSTM\":\n",
    "        hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\n",
    "    else:\n",
    "        hidden_state = tfa.seq2seq.tile_batch(enc_h, multiplier=beam_width)\n",
    "\n",
    "    decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\n",
    "    decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n",
    "\n",
    "    # Instantiate BeamSearchDecoder\n",
    "    decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoder.rnn_cell,beam_width=beam_width, output_layer=decoder.fc)\n",
    "    decoder_embedding_matrix = decoder.embedding.variables[0]\n",
    "\n",
    "    # The BeamSearchDecoder object's call() function takes care of everything.\n",
    "    outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, start_tokens=start_tokens, end_token=end_token, initial_state=decoder_initial_state)\n",
    "    # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
    "    # The final beam predictions are stored in outputs.predicted_id\n",
    "    # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
    "    # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
    "    # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
    "\n",
    "\n",
    "    # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
    "    # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
    "    # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
    "    final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
    "    beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
    "\n",
    "    return final_outputs.numpy(), beam_scores.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_transliterate(word, encoder, decoder, config):\n",
    "  result, beam_scores = beam_evaluate_word(word, encoder, decoder, config, 5)\n",
    "  print(result.shape, beam_scores.shape)\n",
    "  for beam, score in zip(result, beam_scores):\n",
    "    print(beam.shape, score.shape)\n",
    "    output = dataset.target_tokenizer.sequences_to_texts(beam)\n",
    "    output = [a[:a.index('#')] for a in output]\n",
    "    beam_score = [a.sum() for a in score]\n",
    "    print('Input: %s' % (word))\n",
    "    for i in range(len(output)):\n",
    "      print('{} Predicted translation: {}  {}'\n",
    "            .format(i+1, \"\".join(output[i].split(\" \")).replace(\"#\", \"\"), \n",
    "                    beam_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_transliterate('shibobrota', encoder, decoder, default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-treatment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
