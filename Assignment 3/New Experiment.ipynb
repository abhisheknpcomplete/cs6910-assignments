{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complicated-marketing",
   "metadata": {},
   "source": [
    "#### CS20M059 Shibobrota Das | CS20M007 Abhishek Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-block",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incoming-noise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.4.1\n",
      "Using tensorflow Addons: 0.12.1\n",
      "Using keras: 2.4.0\n",
      "Using pandas: 1.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using tensorflow Addons:\",tfa.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-possession",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tired-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-smell",
   "metadata": {},
   "source": [
    "#### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interim-ferry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>बनिए</td>\n",
       "      <td>baniye</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>प्रस्तावित</td>\n",
       "      <td>prastavit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>श्रद्धेय</td>\n",
       "      <td>shradhey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1  2\n",
       "2649        बनिए     baniye  1\n",
       "2434  प्रस्तावित  prastavit  2\n",
       "3826    श्रद्धेय   shradhey  2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-coaching",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "constitutional-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = \"@\"\n",
    "eos = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conceptual-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, batch_size):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch = tf.data.Dataset.from_tensor_slices((self.input_tensor, self.target_tensor)).shuffle(len(self.input_tensor)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incomplete-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransliterationDatatset:\n",
    "    def __init__(self, df_list, problem_type = \"en-hi\", batch_size = 32):\n",
    "        self.problem_type = problem_type\n",
    "        self.input_tokenizer = None\n",
    "        self.target_tokenizer = None\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "        self.batch_size = batch_size\n",
    "        # Load Data\n",
    "        self.load_dataset(df_list)\n",
    "        \n",
    "    def preprocess_word(self, w):\n",
    "        return sos + str(w) + eos\n",
    "    \n",
    "    def create_dataset(self, data_frame):\n",
    "        input_words = []\n",
    "        target_words = []\n",
    "        # Shuffle the data_frame before creating dataset\n",
    "        df_shuffled = shuffle(data_frame)\n",
    "        for x, y in zip(df_shuffled[1], df_shuffled[0]):\n",
    "            input_words.append(self.preprocess_word(x))\n",
    "            target_words.append(self.preprocess_word(y))\n",
    "        return (input_words, target_words)\n",
    "    \n",
    "    def load_dataset(self, df_list):\n",
    "        # df_list should have train -> val -> test in sequence\n",
    "        \n",
    "        self.input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        self.target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        \n",
    "        ds_list = []\n",
    "        \n",
    "        for df in df_list:\n",
    "            # Get the words list\n",
    "            (input_words, target_words) = self.create_dataset(df)\n",
    "            # Fit on the set of words\n",
    "            self.input_tokenizer.fit_on_texts(input_words)\n",
    "            self.target_tokenizer.fit_on_texts(target_words)\n",
    "            ds_list.append((input_words, target_words))\n",
    "                    \n",
    "        self.target_tokenizer.index_word.update({0:\" \"})\n",
    "        self.input_tokenizer.index_word.update({0:\" \"})\n",
    "        \n",
    "        input_word_len = []\n",
    "        target_word_len = []\n",
    "        \n",
    "        tensor_list = []\n",
    "        \n",
    "        for i, (input_words, target_words) in enumerate(ds_list):\n",
    "            input_tensor = self.input_tokenizer.texts_to_sequences(input_words)\n",
    "            target_tensor = self.target_tokenizer.texts_to_sequences(target_words)\n",
    "            tensor_list.append((input_tensor, target_tensor))\n",
    "            input_word_len.append(np.max([len(x) for x in input_tensor]))\n",
    "            target_word_len.append(np.max([len(x) for x in target_tensor]))\n",
    "        \n",
    "        for i, (input_tensor, target_tensor) in enumerate(tensor_list):\n",
    "            \n",
    "            input_tensor = pad_sequences(input_tensor, padding='post', maxlen = np.max(input_word_len))\n",
    "            target_tensor = pad_sequences(target_tensor, padding='post', maxlen = np.max(target_word_len))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.train = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            elif i == 1:\n",
    "                self.val = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            else:\n",
    "                self.test = LexDataset(input_tensor, target_tensor, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bridal-smooth",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TransliterationDatatset([train_df, val_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-liver",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "federal-procurement",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44204, 22), (44204, 21))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset.train.input_tensor.shape, dataset.train.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-arrangement",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sustained-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 22), (4358, 21))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data\n",
    "dataset.val.input_tensor.shape, dataset.val.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-plain",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "drawn-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4502, 22), (4502, 21))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "dataset.test.input_tensor.shape, dataset.test.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-compilation",
   "metadata": {},
   "source": [
    "#### Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "entitled-advocate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "num_encoder_tokens = len(dataset.input_tokenizer.index_word)+1\n",
    "num_decoder_tokens = len(dataset.target_tokenizer.index_word)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-transformation",
   "metadata": {},
   "source": [
    "#### Maximum Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "developing-independence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max seq length\n",
    "max_encoder_seq_length = np.max([dataset.train.input_tensor.shape[1], dataset.val.input_tensor.shape[1], dataset.test.input_tensor.shape[1]])\n",
    "max_decoder_seq_length = np.max([dataset.train.target_tensor.shape[1], dataset.val.target_tensor.shape[1], dataset.test.target_tensor.shape[1]])\n",
    "max_encoder_seq_length, max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-herald",
   "metadata": {},
   "source": [
    "#### Example batch - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "starting-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 22]), TensorShape([32, 21]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset.train.batch))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-banana",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "shared-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, layer_type = \"SimpleRNN\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        self.layer_type = layer_type\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        ##-------- RNN layer in Encoder ------- ##\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.layer = LSTM(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.layer = GRU(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        else:\n",
    "            self.layer = SimpleRNN(self.encoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "\n",
    "    def call(self, inputs, hidden):\n",
    "        inputs = self.embedding(inputs)\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            output, h, c = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, c\n",
    "        else:\n",
    "            output, h = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, None\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            return [tf.zeros((self.batch_size, self.encoder_units)), tf.zeros((self.batch_size, self.encoder_units))]\n",
    "        else:\n",
    "            return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-ebony",
   "metadata": {},
   "source": [
    "#### Test Encoder Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instrumental-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test Encoder Stack\n",
    "\n",
    "# encoder = Encoder(num_encoder_tokens, embedding_dim, units, dataset.batch_size, \"SimpleRNN\")\n",
    "\n",
    "\n",
    "# # sample input\n",
    "# sample_hidden = encoder.initialize_hidden_state()\n",
    "# sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "# print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "# if encoder.layer_type == \"LSTM\":\n",
    "#     print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-burner",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "listed-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size, layer_type, attention_type='luong'):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.decoder_units = decoder_units\n",
    "        self.layer_type = layer_type\n",
    "        self.attention_type = attention_type\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Final Dense layer on which softmax will be applied\n",
    "        self.fc = Dense(vocab_size)\n",
    "        \n",
    "        # fundamental cell for decoder recurrent structure\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.decoder_rnn_cell = LSTMCell(self.decoder_units)\n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.decoder_rnn_cell = GRUCell(self.decoder_units)\n",
    "        else:\n",
    "            self.decoder_rnn_cell = SimpleRNNCell(self.decoder_units)\n",
    "\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention = self.build_attention_mechanism(self.decoder_units, \n",
    "                                                        None, self.batch_size*[max_decoder_seq_length], \n",
    "                                                        self.attention_type)\n",
    "\n",
    "        # Wrap attention mechanism with the fundamental rnn cell of decoder\n",
    "        self.rnn_cell = self.build_rnn_cell()\n",
    "\n",
    "        # Define the decoder with respect to fundamental rnn cell\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
    "\n",
    "        \n",
    "    def build_rnn_cell(self):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell,\n",
    "                                               self.attention,\n",
    "                                               attention_layer_size = self.decoder_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_attention_mechanism(self, decoder_units, memory, \n",
    "                                  memory_sequence_length, attention_type='luong'):\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=decoder_units, memory = memory, memory_sequence_length = memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=decoder_units, memory = memory, memory_sequence_length = memory_sequence_length)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state, Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = self.batch_size, dtype = Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state = encoder_state)\n",
    "        return decoder_initial_state\n",
    "    \n",
    "    def call(self, inputs, initial_state):\n",
    "        inputs = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(inputs, initial_state = initial_state, sequence_length = self.batch_size*[max_decoder_seq_length-1])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-walter",
   "metadata": {},
   "source": [
    "#### Test decoder stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "balanced-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test decoder stack\n",
    "\n",
    "# decoder = Decoder(num_decoder_tokens, embedding_dim, units, dataset.batch_size, \"SimpleRNN\", 'luong')\n",
    "# sample_x = tf.random.uniform((dataset.batch_size, max_decoder_seq_length))\n",
    "# decoder.attention.setup_memory(sample_output)\n",
    "# if decoder.layer_type == \"LSTM\":\n",
    "#     initial_state = decoder.build_initial_state(dataset.batch_size, [sample_h, sample_c], tf.float32)\n",
    "# else:\n",
    "#     initial_state = decoder.build_initial_state(dataset.batch_size, sample_h, tf.float32)\n",
    "\n",
    "\n",
    "# sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "# print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-eagle",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "danish-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"layer_type\": \"LSTM\",\n",
    "    \"units\": 128,\n",
    "    \"embedding_dim\": 16,\n",
    "    \"optimiser\": \"nadam\",\n",
    "    \"num_encoders\": 1,\n",
    "    \"num_decoders\": 1,\n",
    "    \"dropout\": 0.2,\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": dataset.batch_size,\n",
    "    \"attention\": \"luong\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-green",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fatal-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    cross_entropy = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-anime",
   "metadata": {},
   "source": [
    "#### Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "going-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(real, pred):\n",
    "    # real shape = (BATCH_SIZE, max_length_output)\n",
    "    # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
    "    predictions = tf.cast(tf.argmax(pred, axis=2), tf.int32)\n",
    "    correct_preds = tf.equal(predictions, real)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-alias",
   "metadata": {},
   "source": [
    "#### Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "concrete-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tribal-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printf(data):\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.write(data)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-auckland",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "proprietary-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_dataset, val_dataset):\n",
    "    ## Encoder\n",
    "    encoder = Encoder(num_encoder_tokens, config[\"embedding_dim\"], \n",
    "                      config[\"units\"], config[\"batch_size\"], \n",
    "                      config[\"layer_type\"])\n",
    "\n",
    "    ## Decoder\n",
    "    decoder = Decoder(num_decoder_tokens, config[\"embedding_dim\"], \n",
    "                      config[\"units\"], config[\"batch_size\"], \n",
    "                      config[\"layer_type\"], config[\"attention\"])\n",
    "    \n",
    "    ## Optimizer\n",
    "    optimizer = keras.optimizers.Nadam()\n",
    "\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                     encoder=encoder,\n",
    "                                     decoder=decoder)\n",
    "\n",
    "    EPOCHS = 2\n",
    "    BATCH_SIZE = config[\"batch_size\"]\n",
    "    steps_per_epoch = np.shape(dataset.train.input_tensor)[0]//dataset.batch_size\n",
    "    val_steps_per_epoch = np.shape(val_dataset.input_tensor)[0]//dataset.batch_size\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "\n",
    "        train_dataset.batch.shuffle(BATCH_SIZE)\n",
    "        val_dataset.batch.shuffle(BATCH_SIZE)\n",
    "\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        val_total_loss = 0\n",
    "        val_total_accuracy = 0\n",
    "        \n",
    "        # Training Loop\n",
    "        for (batch, (inp, targ)) in enumerate(train_dataset.batch.take(steps_per_epoch)):        \n",
    "            batch_loss = 0\n",
    "            accuracy = 0\n",
    "            with GradientTape() as tape:\n",
    "                enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "                dec_input = targ[ : , :-1 ]       # Ignore '#' token\n",
    "                real = targ[ : , 1: ]             # ignore '@' token\n",
    "\n",
    "                # Set the AttentionMechanism object with encoder_outputs\n",
    "                decoder.attention.setup_memory(enc_output)\n",
    "\n",
    "                # Create AttentionWrapperState as initial_state for decoder\n",
    "                if decoder.layer_type == \"LSTM\":\n",
    "                    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "                else:\n",
    "                    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, enc_h, tf.float32)\n",
    "                \n",
    "                pred = decoder(dec_input, decoder_initial_state)\n",
    "                logits = pred.rnn_output\n",
    "                batch_loss = loss_function(real, logits)\n",
    "\n",
    "                # Experiment for Accuracy\n",
    "                accuracy = calc_accuracy(real, logits)\n",
    "\n",
    "\n",
    "            variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "            gradients = tape.gradient(batch_loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "            total_loss += batch_loss\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "            printf(f\"Training: {(100 * batch / len(dataset.train.batch.take(steps_per_epoch))):.2f}% Accuracy: {(total_accuracy / batch):.4f} Loss: {(total_loss / batch):.4f}\")\n",
    "        \n",
    "        printf(\"\\n\")\n",
    "        \n",
    "        # Validation Loop\n",
    "        for (val_batch, (inp, targ)) in enumerate(val_dataset.batch.take(steps_per_epoch)):        \n",
    "            val_batch_loss = 0\n",
    "            val_accuracy = 0\n",
    "            \n",
    "            enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "\n",
    "            dec_input = targ[ : , :-1 ]       # Ignore '#' token\n",
    "            real = targ[ : , 1: ]             # ignore '@' token\n",
    "\n",
    "            # Set the AttentionMechanism object with encoder_outputs\n",
    "            decoder.attention.setup_memory(enc_output)\n",
    "\n",
    "            # Create AttentionWrapperState as initial_state for decoder\n",
    "            if decoder.layer_type == \"LSTM\":\n",
    "                decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "            else:\n",
    "                decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, enc_h, tf.float32)\n",
    "\n",
    "            pred = decoder(dec_input, decoder_initial_state)\n",
    "            logits = pred.rnn_output\n",
    "            \n",
    "            val_batch_loss = loss_function(real, logits)\n",
    "            val_accuracy = calc_accuracy(real, logits)\n",
    "            \n",
    "            val_total_loss += val_batch_loss\n",
    "            val_total_accuracy += val_accuracy\n",
    "            \n",
    "            printf(f\"Validating: {(100 * val_batch / len(val_dataset.batch.take(val_steps_per_epoch))):.2f}% Accuracy: {(val_total_accuracy / val_batch):.4f} Loss: {(val_total_loss / val_batch):.4f}\")\n",
    "        \n",
    "        printf(\"\\n\")\n",
    "        # saving (checkpoint) the model every epochs\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print(f'Loss {(total_loss / steps_per_epoch):.4f} Accuracy {(total_accuracy / steps_per_epoch):.4f}')\n",
    "        print(f'Val Loss {(val_total_loss / val_steps_per_epoch):.4f} Val Accuracy {(val_total_accuracy / val_steps_per_epoch):.4f}')\n",
    "        print(f'Time taken for this epoch {(time.time() - start):.4f} sec\\n')\n",
    "        \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training: 7.46% Accuracy: 0.0660 Loss: 1.2185"
     ]
    }
   ],
   "source": [
    "encoder, decoder = train_model(default_config, dataset.train, dataset.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-turning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
