{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f85e9d-215f-45c6-95ad-d56e6e3d3759",
   "metadata": {
    "id": "33f85e9d-215f-45c6-95ad-d56e6e3d3759"
   },
   "source": [
    "#### CS20M059 Shibobrota Das | CS20M007 Abhishek Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700a5ec-7c66-45f5-9539-a593bb36ddc6",
   "metadata": {
    "id": "6700a5ec-7c66-45f5-9539-a593bb36ddc6"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08fb4b5-e93b-4c82-bc45-e2a22a7dee95",
   "metadata": {
    "id": "a08fb4b5-e93b-4c82-bc45-e2a22a7dee95"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c70406c-fe4d-43f1-93a4-9dc617b301da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c70406c-fe4d-43f1-93a4-9dc617b301da",
    "outputId": "bf4e446f-d7f6-4429-8b83-c8f3e59afd05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numpy: 1.19.5\n",
      "Using tensorflow: 2.5.0\n",
      "Using keras: 2.5.0\n",
      "Using pandas: 1.1.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, SimpleRNNCell, LSTMCell, GRUCell\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "import wandb\n",
    "# import nltk\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "print(\"Using numpy:\",np.__version__)\n",
    "print(\"Using tensorflow:\",tf.__version__)\n",
    "print(\"Using keras:\",keras.__version__)\n",
    "print(\"Using pandas:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddf43393-e89f-46f4-a711-f2e7078e9e85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "ddf43393-e89f-46f4-a711-f2e7078e9e85",
    "outputId": "00b9eadc-b8c9-40d6-b927-80b2dbfda543"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">tough-dust-434</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203\" target=\"_blank\">https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/30qqezv9\" target=\"_blank\">https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/30qqezv9</a><br/>\n",
       "                Run data is saved locally in <code>/content/drive/My Drive/A3-checkpoints/wandb/run-20210525_180037-30qqezv9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(30qqezv9)</h1><iframe src=\"https://wandb.ai/iitm-cs6910-jan-may-2021-cs20m059-cs20m007/Assignment%203/runs/30qqezv9\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f33665c7fd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='Assignment 3', entity='iitm-cs6910-jan-may-2021-cs20m059-cs20m007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd226e1-96b2-4440-a310-15a8cf2f0035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd226e1-96b2-4440-a310-15a8cf2f0035",
    "outputId": "e25b5754-06ac-408e-876f-315283ffe314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive/DL-A3 Dataset/dakshina_dataset_v1.0/hi\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/My Drive/DL-A3 Dataset/dakshina_dataset_v1.0/hi/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c92d9-374e-4e0f-b2d1-7f17d895cc04",
   "metadata": {
    "id": "559c92d9-374e-4e0f-b2d1-7f17d895cc04"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee85d467-1fac-40d1-a7ca-b00faf2d3d4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee85d467-1fac-40d1-a7ca-b00faf2d3d4b",
    "outputId": "eafd7ad7-6830-4367-cfa8-7ae8f6881feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded to Dataframes!\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"./lexicons/hi.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "train_df = pd.read_csv(\"./lexicons/hi.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "test_df = pd.read_csv(\"./lexicons/hi.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "print(\"Data Loaded to Dataframes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ae78d1-de5a-435a-8b39-088bd63f8e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13ae78d1-de5a-435a-8b39-088bd63f8e2c",
    "outputId": "8809cb8c-5c09-420f-9d2e-71997c529b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/A3-checkpoints\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/A3-checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6b5e6-844e-4fb9-9eeb-bcedd0cf6fd1",
   "metadata": {
    "id": "caa6b5e6-844e-4fb9-9eeb-bcedd0cf6fd1"
   },
   "source": [
    "#### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fefa85bd-2299-4503-8d29-458451185e8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "fefa85bd-2299-4503-8d29-458451185e8f",
    "outputId": "d6f7206f-ce0c-46ee-98f9-00254fffd746"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>कुशवाहा</td>\n",
       "      <td>kushvaha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41944</th>\n",
       "      <td>सेंसर्स</td>\n",
       "      <td>sensors</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25312</th>\n",
       "      <td>फलोदी</td>\n",
       "      <td>phalodi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1  2\n",
       "8322   कुशवाहा  kushvaha  1\n",
       "41944  सेंसर्स   sensors  3\n",
       "25312    फलोदी   phalodi  1"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e8bdb-9997-43b6-ba7e-e05879c1c4c0",
   "metadata": {
    "id": "627e8bdb-9997-43b6-ba7e-e05879c1c4c0"
   },
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53abf538-55d3-46e0-9532-f0aded169217",
   "metadata": {
    "id": "53abf538-55d3-46e0-9532-f0aded169217"
   },
   "outputs": [],
   "source": [
    "sos = \"@\"\n",
    "eos = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7035ff0-c322-4ef6-98ac-eae0416ad3a7",
   "metadata": {
    "id": "e7035ff0-c322-4ef6-98ac-eae0416ad3a7"
   },
   "outputs": [],
   "source": [
    "class LexDataset:\n",
    "    def __init__(self, input_tensor, target_tensor, batch_size):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch = tf.data.Dataset.from_tensor_slices((self.input_tensor, self.target_tensor)).shuffle(len(self.input_tensor)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce3cd7e2-7e30-44bb-8a27-77dbf944bea0",
   "metadata": {
    "id": "ce3cd7e2-7e30-44bb-8a27-77dbf944bea0"
   },
   "outputs": [],
   "source": [
    "class TransliterationDatatset:\n",
    "    def __init__(self, df_list, batch_size = 64):\n",
    "        \n",
    "        self.input_tokenizer = None\n",
    "        self.target_tokenizer = None\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "        self.batch_size = batch_size\n",
    "        # Load Data\n",
    "        self.load_dataset(df_list)\n",
    "        # Other parameters\n",
    "        self.num_input_tokens = len(self.input_tokenizer.index_word)+1\n",
    "        self.num_target_tokens = len(self.target_tokenizer.index_word)+1\n",
    "        self.max_input_seq_length = np.max([self.train.input_tensor.shape[1], self.val.input_tensor.shape[1], self.test.input_tensor.shape[1]])\n",
    "        self.max_target_seq_length = np.max([self.train.target_tensor.shape[1], self.val.target_tensor.shape[1], self.test.target_tensor.shape[1]])\n",
    "        \n",
    "    def preprocess_word(self, w):\n",
    "        return sos + str(w) + eos\n",
    "    \n",
    "    def print_input(self, tensor):\n",
    "        for t in tensor:\n",
    "            if t != 0:\n",
    "                print(f'{t} ----> {self.input_tokenizer.index_word[t]}')\n",
    "                \n",
    "    def print_target(self, tensor):\n",
    "        for t in tensor:\n",
    "            if t != 0:\n",
    "                print(f'{t} ----> {self.target_tokenizer.index_word[t]}')\n",
    "    \n",
    "    def create_dataset(self, data_frame):\n",
    "        input_words = []\n",
    "        target_words = []\n",
    "        # Shuffle the data_frame before creating dataset\n",
    "        df = data_frame\n",
    "        for i in range(5):\n",
    "            df = shuffle(df)\n",
    "        for x, y in zip(df[1], df[0]):\n",
    "            input_words.append(self.preprocess_word(x))\n",
    "            target_words.append(self.preprocess_word(y))\n",
    "        return (input_words, target_words)\n",
    "    \n",
    "    def load_dataset(self, df_list):\n",
    "        # df_list should have train -> val -> test in sequence\n",
    "        \n",
    "        self.input_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        self.target_tokenizer = Tokenizer(num_words = None, char_level = True)\n",
    "        \n",
    "        ds_list = []\n",
    "        \n",
    "        for df in df_list:\n",
    "            # Get the words list\n",
    "            (input_words, target_words) = self.create_dataset(df)\n",
    "            # Fit on the set of words\n",
    "            self.input_tokenizer.fit_on_texts(input_words)\n",
    "            self.target_tokenizer.fit_on_texts(target_words)\n",
    "            ds_list.append((input_words, target_words))\n",
    "                    \n",
    "        self.target_tokenizer.index_word.update({0:\" \"})\n",
    "        self.input_tokenizer.index_word.update({0:\" \"})\n",
    "        \n",
    "        input_word_len = []\n",
    "        target_word_len = []\n",
    "        \n",
    "        tensor_list = []\n",
    "        \n",
    "        for i, (input_words, target_words) in enumerate(ds_list):\n",
    "            input_tensor = self.input_tokenizer.texts_to_sequences(input_words)\n",
    "            target_tensor = self.target_tokenizer.texts_to_sequences(target_words)\n",
    "            tensor_list.append((input_tensor, target_tensor))\n",
    "            input_word_len.append(np.max([len(x) for x in input_tensor]))\n",
    "            target_word_len.append(np.max([len(x) for x in target_tensor]))\n",
    "        \n",
    "        for i, (input_tensor, target_tensor) in enumerate(tensor_list):\n",
    "            \n",
    "            input_tensor = pad_sequences(input_tensor, padding='post', maxlen = np.max(input_word_len))\n",
    "            target_tensor = pad_sequences(target_tensor, padding='post', maxlen = np.max(target_word_len))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.train = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            elif i == 1:\n",
    "                self.val = LexDataset(input_tensor, target_tensor, self.batch_size)\n",
    "            else:\n",
    "                self.test = LexDataset(input_tensor, target_tensor, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b06317-dab4-4455-812e-1b34679e27b1",
   "metadata": {
    "id": "63b06317-dab4-4455-812e-1b34679e27b1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TransliterationDatatset([train_df, val_df, test_df], 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb817ef-9206-4341-807a-4b4db2113340",
   "metadata": {
    "id": "1fb817ef-9206-4341-807a-4b4db2113340"
   },
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da1956c-d5be-4d10-a263-f565341e5d6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1da1956c-d5be-4d10-a263-f565341e5d6a",
    "outputId": "c4728080-4600-4f71-c8d0-94fa81d6b8df",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44204, 22), (44204, 21))"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset.train.input_tensor.shape, dataset.train.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a008930-d6da-4be0-898c-153f49b8845a",
   "metadata": {
    "id": "3a008930-d6da-4be0-898c-153f49b8845a"
   },
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c2a7df-ec58-40b6-9ba1-6b7782fdfa0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3c2a7df-ec58-40b6-9ba1-6b7782fdfa0c",
    "outputId": "c525913c-0706-4507-dd97-91ab352c707d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 22), (4358, 21))"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data\n",
    "dataset.val.input_tensor.shape, dataset.val.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da416c97-6ef6-4855-8968-dfcd1fe8ff5a",
   "metadata": {
    "id": "da416c97-6ef6-4855-8968-dfcd1fe8ff5a"
   },
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa011970-5547-4783-a89d-8ab8c3438fa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa011970-5547-4783-a89d-8ab8c3438fa6",
    "outputId": "f23e90ca-c0d9-4527-f743-e98e3218ef4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4502, 22), (4502, 21))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "dataset.test.input_tensor.shape, dataset.test.target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ada4f-733d-4301-93b2-1ade66cde9a8",
   "metadata": {
    "id": "8a7ada4f-733d-4301-93b2-1ade66cde9a8"
   },
   "source": [
    "#### Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba2c1c4-7fb6-454b-8210-13398ed7406b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bba2c1c4-7fb6-454b-8210-13398ed7406b",
    "outputId": "6a22ae86-f896-454e-ca1c-6dc499e3a7ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 67)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "dataset.num_input_tokens, dataset.num_target_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a249a5-d5ea-46c6-ab4f-a7d0e08b05f3",
   "metadata": {
    "id": "01a249a5-d5ea-46c6-ab4f-a7d0e08b05f3"
   },
   "source": [
    "#### Maximum Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c96afcb-d6ff-4b44-89f2-5d0797709ce4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c96afcb-d6ff-4b44-89f2-5d0797709ce4",
    "outputId": "ac91b350-bee9-47e0-ca4f-e5df9e4602a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max seq length\n",
    "dataset.max_input_seq_length, dataset.max_target_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24fd33-e9fd-47c7-be52-62705caf2ebc",
   "metadata": {
    "id": "ef24fd33-e9fd-47c7-be52-62705caf2ebc"
   },
   "source": [
    "#### Example batch - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c95122-8a50-482b-ae5d-994a74f31765",
   "metadata": {
    "id": "a3c95122-8a50-482b-ae5d-994a74f31765"
   },
   "outputs": [],
   "source": [
    "# example_input_batch, example_target_batch = next(iter(dataset.train.batch))\n",
    "# example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc25ddd3-8cd9-4f65-98de-b4f5bddf8c13",
   "metadata": {
    "id": "cc25ddd3-8cd9-4f65-98de-b4f5bddf8c13"
   },
   "outputs": [],
   "source": [
    "# dataset.print_input(example_input_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc385626-2c47-48cf-88c6-a8bce1ab1cdb",
   "metadata": {
    "id": "cc385626-2c47-48cf-88c6-a8bce1ab1cdb"
   },
   "outputs": [],
   "source": [
    "# dataset.print_target(example_target_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81646f07-05bf-4c75-aaf4-ce964bf9e458",
   "metadata": {
    "id": "81646f07-05bf-4c75-aaf4-ce964bf9e458"
   },
   "source": [
    "## Encoder and Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29f2c233-4f9a-471a-8ff9-dfe5950a4963",
   "metadata": {
    "id": "29f2c233-4f9a-471a-8ff9-dfe5950a4963"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, dropout=0.2, layer_type=\"GRU\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "        ##-------- RNN layer in Encoder ------- ##\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.layer = LSTM(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "            \n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.layer = GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "           \n",
    "        else:\n",
    "            self.layer = SimpleRNN(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs, hidden):\n",
    "        inputs = self.embedding(inputs)\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            output, h, c = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, c\n",
    "        else:\n",
    "            output, h = self.layer(inputs, initial_state = hidden)\n",
    "            return output, h, None\n",
    "\n",
    "    def initialize_hidden_state(self, batch_size):\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            return [tf.zeros((batch_size, self.enc_units)), tf.zeros((batch_size, self.enc_units))]\n",
    "        else:\n",
    "            return tf.zeros((batch_size, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59648301-2c83-4d6e-b066-3bb2ff53650c",
   "metadata": {
    "id": "59648301-2c83-4d6e-b066-3bb2ff53650c"
   },
   "outputs": [],
   "source": [
    "# vocab_inp_size = dataset.num_input_tokens\n",
    "# embedding_dim = 64\n",
    "# units = 256\n",
    "# BATCH_SIZE = dataset.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8911625-ecf9-41b6-9234-7f241a71dd4a",
   "metadata": {
    "id": "a8911625-ecf9-41b6-9234-7f241a71dd4a"
   },
   "outputs": [],
   "source": [
    "# encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# # sample input\n",
    "# sample_hidden = encoder.initialize_hidden_state(BATCH_SIZE)\n",
    "# sample_output, sample_hidden, _ = encoder(example_input_batch, sample_hidden)\n",
    "# print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
    "# print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cd28da3-6384-4280-9c67-9d542884f55a",
   "metadata": {
    "id": "4cd28da3-6384-4280-9c67-9d542884f55a"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "955fd636-70c1-4208-b59b-1b19d3090e50",
   "metadata": {
    "id": "955fd636-70c1-4208-b59b-1b19d3090e50"
   },
   "outputs": [],
   "source": [
    "# attention_layer = BahdanauAttention(10)\n",
    "# attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "# print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
    "# print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adbd8f1a-53b4-4d8d-bff6-478f2718bcd4",
   "metadata": {
    "id": "adbd8f1a-53b4-4d8d-bff6-478f2718bcd4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, dropout=0.2, layer_type=\"GRU\"):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.layer_type = layer_type\n",
    "        \n",
    "        ##-------- RNN layer in Decoder ------- ##\n",
    "        if self.layer_type == \"LSTM\":\n",
    "            self.layer = LSTM(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "            \n",
    "        elif self.layer_type == \"GRU\":\n",
    "            self.layer = GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "           \n",
    "        else:\n",
    "            self.layer = SimpleRNN(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       dropout = dropout,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU/LSTM/SimpleRNN\n",
    "        if self.layer_type != \"LSTM\":\n",
    "            output, state_h = self.layer(x)\n",
    "        else:\n",
    "            output, state_h, state_c = self.layer(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        # return x, state\n",
    "        if self.layer_type != \"LSTM\":\n",
    "            return x, state_h, None, attention_weights\n",
    "        else:\n",
    "            return x, state_h, state_c, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7fb80f6-6d51-4b88-89aa-b10d4cbcb950",
   "metadata": {
    "id": "f7fb80f6-6d51-4b88-89aa-b10d4cbcb950"
   },
   "outputs": [],
   "source": [
    "# vocab_tar_size = dataset.num_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4dd296f-1d52-4b1a-9caa-e56ae23af6ea",
   "metadata": {
    "id": "c4dd296f-1d52-4b1a-9caa-e56ae23af6ea"
   },
   "outputs": [],
   "source": [
    "# decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample_decoder_output, _, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "#                                       sample_hidden, sample_output)\n",
    "\n",
    "# print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d718ae-5b4a-472f-9d62-e3b72a468217",
   "metadata": {
    "id": "51d718ae-5b4a-472f-9d62-e3b72a468217"
   },
   "source": [
    "## Optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d21003ab-70ee-455d-a0bd-4e16a87f6c70",
   "metadata": {
    "id": "d21003ab-70ee-455d-a0bd-4e16a87f6c70"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9MXMGXggqjam",
   "metadata": {
    "id": "9MXMGXggqjam"
   },
   "outputs": [],
   "source": [
    "def accuracy(real, pred):\n",
    "    real = tf.cast(real, tf.int32)\n",
    "    pred = tf.cast(pred, tf.int32)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(real, pred), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e633463-5d0c-4080-9e0d-5cc8cb88a9b9",
   "metadata": {
    "id": "7e633463-5d0c-4080-9e0d-5cc8cb88a9b9"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90973b6a-e060-4e22-94f6-2400e7d700f2",
   "metadata": {
    "id": "90973b6a-e060-4e22-94f6-2400e7d700f2"
   },
   "outputs": [],
   "source": [
    "def train_one_step():\n",
    "    @tf.function\n",
    "    def train_step(encoder, decoder, inp, targ, enc_hidden, is_val=False):\n",
    "        loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden, enc_cell = encoder(inp, enc_hidden)\n",
    "\n",
    "            dec_hidden, dec_cell = enc_hidden, enc_cell\n",
    "\n",
    "            dec_input = tf.expand_dims([dataset.target_tokenizer.word_index[sos]] * inp.shape[0], 1)\n",
    "\n",
    "            pred = None\n",
    "\n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "                if t == 1:\n",
    "                    pred = tf.expand_dims(tf.argmax(predictions, axis=-1), 1)\n",
    "                else:\n",
    "                    pred = tf.concat([pred, tf.expand_dims(tf.argmax(predictions, axis=-1), 1)], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        batch_accuracy = accuracy(targ[:, 1:], pred)\n",
    "\n",
    "        if not is_val:\n",
    "            variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss, batch_accuracy\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7E4vmvoXWozl",
   "metadata": {
    "id": "7E4vmvoXWozl"
   },
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"layer_type\": \"LSTM\",\n",
    "    \"units\": 256,\n",
    "    \"embedding_dim\": 16,\n",
    "    \"optimiser\": \"nadam\",\n",
    "    \"epochs\": 20,\n",
    "    \"dropout\": 0.0,\n",
    "    \"batch_size\": dataset.batch_size,\n",
    "    \"num_layers\": 1,\n",
    "    \"has_attention\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "J61uaHm4W196",
   "metadata": {
    "id": "J61uaHm4W196"
   },
   "outputs": [],
   "source": [
    "def log_wandb(data):\n",
    "    wandb.log(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4HvRdo-hW5Ms",
   "metadata": {
    "id": "4HvRdo-hW5Ms"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"Assignment 3 - With Attention Single Layered \" + str(datetime.datetime.now().replace(microsecond=0).isoformat()),\n",
    "    \"method\": \"random\",\n",
    "    \"metric\":{\n",
    "        \"name\": \"loss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"project\": 'Assignment 3',\n",
    "    \"parameters\": {\n",
    "        \"layer_type\": {\n",
    "            \"values\": [\"GRU\", \"LSTM\", \"SimpleRNN\"]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"values\": [0.0, 0.2]\n",
    "        },\n",
    "        \"units\": {\n",
    "            \"values\": [256, 512]\n",
    "        },\n",
    "        \"embedding_dim\": {\n",
    "            \"values\": [64, 128]\n",
    "        },\n",
    "        \"optimiser\": {\n",
    "            \"values\": [\"nadam\"]\n",
    "        },\n",
    "        \"epochs\": {\n",
    "            \"values\": [20]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [dataset.batch_size]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"values\": [1]\n",
    "        },\n",
    "        \"has_attention\": {\n",
    "            \"values\": [True]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "VeuZNBBtXK0a",
   "metadata": {
    "id": "VeuZNBBtXK0a"
   },
   "outputs": [],
   "source": [
    "def train(dataset, config, callback=None):\n",
    "\n",
    "    run_name = \"\".join(f\"{a}:{b} \" for (a, b) in config.items())\n",
    "    print(run_name)\n",
    "    # wandb.run.name = run_name\n",
    "\n",
    "    train_dataset = dataset.train\n",
    "    val_dataset = dataset.val\n",
    "\n",
    "    EPOCHS = config[\"epochs\"]\n",
    "    BATCH_SIZE = config[\"batch_size\"]\n",
    "    steps_per_epoch = len(train_dataset.input_tensor)//BATCH_SIZE\n",
    "    val_steps_per_epoch = len(val_dataset.input_tensor)//BATCH_SIZE\n",
    "    embedding_dim = config[\"embedding_dim\"]     \n",
    "    units = config[\"units\"]\n",
    "    layer_type = config[\"layer_type\"]\n",
    "    num_layers = config[\"num_layers\"]\n",
    "    dropout = config[\"dropout\"]\n",
    "\n",
    "    # Encoder\n",
    "    encoder = Encoder(dataset.num_input_tokens, embedding_dim, units, BATCH_SIZE, dropout, layer_type)\n",
    "    # Decoder\n",
    "    decoder = Decoder(dataset.num_target_tokens, embedding_dim, units, BATCH_SIZE, dropout, layer_type)\n",
    "\n",
    "    train_step = train_one_step()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        enc_hidden = encoder.initialize_hidden_state(BATCH_SIZE)\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        val_total_loss = 0\n",
    "        val_total_accuracy = 0\n",
    "\n",
    "        train_dataset.batch.shuffle(BATCH_SIZE*10)\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(train_dataset.batch.take(steps_per_epoch)):\n",
    "            # Step Train\n",
    "            batch_loss, batch_accuracy = train_step(encoder, decoder, inp, targ, enc_hidden)\n",
    "            total_loss += batch_loss\n",
    "            total_accuracy += batch_accuracy\n",
    "            if batch % 100 == 0 or batch == steps_per_epoch-1:\n",
    "                print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f} Accuracy {batch_accuracy:.4f}')\n",
    "            \n",
    "            if callback != None:\n",
    "                callback({\"attn epoch\":epoch+1, \"attn loss\": batch_loss.numpy(), \"attn accuracy\":batch_accuracy})\n",
    "\n",
    "        print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f} Acc {total_accuracy/steps_per_epoch:.4f}')\n",
    "        print(f'Time taken for 1 epoch {time.time()-start:.4f} sec\\n')\n",
    "        if callback != None:\n",
    "            callback({\"ep attn loss\": total_loss/steps_per_epoch, \"ep attn accuracy\": total_accuracy/steps_per_epoch})\n",
    "\n",
    "        val_dataset.batch.shuffle(BATCH_SIZE*10)\n",
    "        start = time.time()\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(val_dataset.batch.take(val_steps_per_epoch)):\n",
    "            val_batch_loss, val_batch_accuracy = train_step(encoder, decoder, inp, targ, enc_hidden, True)\n",
    "            val_total_loss += val_batch_loss\n",
    "            val_total_accuracy += val_batch_accuracy\n",
    "\n",
    "            if batch % 100 == 0 or batch == val_steps_per_epoch-1:\n",
    "                print(f'Epoch {epoch+1} Batch {batch} Val Loss {val_batch_loss.numpy():.4f} Val Accuracy {val_batch_accuracy:.4f}')\n",
    "\n",
    "            if callback != None:\n",
    "                callback({\"epoch\":epoch+1, \"attn val loss\": batch_loss.numpy(), \"attn val accuracy\":batch_accuracy})\n",
    "\n",
    "        print(f'Epoch {epoch+1} Val Loss {val_total_loss/val_steps_per_epoch:.4f} Val Acc {val_total_accuracy/val_steps_per_epoch:.4f}')\n",
    "        print(f'Time taken for 1 epoch {time.time()-start:.4f} sec\\n')\n",
    "\n",
    "        if callback != None:\n",
    "            callback({\"ep attn val loss\": val_total_loss/val_steps_per_epoch, \"ep attn val accuracy\": val_total_accuracy/val_steps_per_epoch})\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "h2JBZTUseQGy",
   "metadata": {
    "id": "h2JBZTUseQGy"
   },
   "outputs": [],
   "source": [
    "# enc, dec = train(dataset, default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "xt0ItJqAhN2p",
   "metadata": {
    "id": "xt0ItJqAhN2p"
   },
   "outputs": [],
   "source": [
    "def sweep():\n",
    "\n",
    "    wandb.init(config=default_config, magic=True, project='Assignment 3', entity='iitm-cs6910-jan-may-2021-cs20m059-cs20m007')\n",
    "    config = wandb.config\n",
    "    \n",
    "    encoder, decoder = train(dataset, config, log_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "XD7vaY6ohTQ4",
   "metadata": {
    "id": "XD7vaY6ohTQ4"
   },
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project='Assignment 3', entity='iitm-cs6910-jan-may-2021-cs20m059-cs20m007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "R5T-Mu-chV8o",
   "metadata": {
    "id": "R5T-Mu-chV8o"
   },
   "outputs": [],
   "source": [
    "# wandb.agent(\"34ip8f2w\", function=sweep, project='Assignment 3', entity='iitm-cs6910-jan-may-2021-cs20m059-cs20m007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "j4jZPCsHjhS2",
   "metadata": {
    "id": "j4jZPCsHjhS2"
   },
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"layer_type\": \"LSTM\",\n",
    "    \"units\": 512,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"optimiser\": \"nadam\",\n",
    "    \"epochs\": 20,\n",
    "    \"dropout\": 0.0,\n",
    "    \"batch_size\": dataset.batch_size,\n",
    "    \"num_layers\": 1,\n",
    "    \"has_attention\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "QvvWJi1ijmAP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QvvWJi1ijmAP",
    "outputId": "0eab8156-dd5b-48da-f02a-367d9745966c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_type:LSTM units:512 embedding_dim:128 optimiser:nadam epochs:20 dropout:0.0 batch_size:128 num_layers:1 has_attention:True \n",
      "Epoch 1 Batch 0 Loss 1.4970 Accuracy 0.0250\n",
      "Epoch 1 Batch 100 Loss 1.0005 Accuracy 0.1012\n",
      "Epoch 1 Batch 200 Loss 0.9360 Accuracy 0.1070\n",
      "Epoch 1 Batch 300 Loss 0.7914 Accuracy 0.1305\n",
      "Epoch 1 Batch 344 Loss 0.7178 Accuracy 0.1543\n",
      "Epoch 1 Loss 0.9399 Acc 0.0989\n",
      "Time taken for 1 epoch 127.4003 sec\n",
      "\n",
      "Epoch 1 Batch 0 Val Loss 0.7201 Val Accuracy 0.1340\n",
      "Epoch 1 Batch 33 Val Loss 0.6507 Val Accuracy 0.1512\n",
      "Epoch 1 Val Loss 0.6775 Val Acc 0.1467\n",
      "Time taken for 1 epoch 13.6325 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6962 Accuracy 0.1570\n",
      "Epoch 2 Batch 100 Loss 0.4729 Accuracy 0.2066\n",
      "Epoch 2 Batch 200 Loss 0.3535 Accuracy 0.2531\n",
      "Epoch 2 Batch 300 Loss 0.3026 Accuracy 0.2785\n",
      "Epoch 2 Batch 344 Loss 0.2618 Accuracy 0.2848\n",
      "Epoch 2 Loss 0.4122 Acc 0.2374\n",
      "Time taken for 1 epoch 81.9164 sec\n",
      "\n",
      "Epoch 2 Batch 0 Val Loss 0.2446 Val Accuracy 0.2555\n",
      "Epoch 2 Batch 33 Val Loss 0.2421 Val Accuracy 0.2754\n",
      "Epoch 2 Val Loss 0.2604 Val Acc 0.2658\n",
      "Time taken for 1 epoch 3.0183 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.2806 Accuracy 0.2840\n",
      "Epoch 3 Batch 100 Loss 0.2009 Accuracy 0.2930\n",
      "Epoch 3 Batch 200 Loss 0.2118 Accuracy 0.2961\n",
      "Epoch 3 Batch 300 Loss 0.2133 Accuracy 0.3063\n",
      "Epoch 3 Batch 344 Loss 0.1662 Accuracy 0.3172\n",
      "Epoch 3 Loss 0.2155 Acc 0.2945\n",
      "Time taken for 1 epoch 72.3211 sec\n",
      "\n",
      "Epoch 3 Batch 0 Val Loss 0.2149 Val Accuracy 0.2625\n",
      "Epoch 3 Batch 33 Val Loss 0.2215 Val Accuracy 0.2727\n",
      "Epoch 3 Val Loss 0.2078 Val Acc 0.2828\n",
      "Time taken for 1 epoch 2.8610 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2251 Accuracy 0.2965\n",
      "Epoch 4 Batch 100 Loss 0.1798 Accuracy 0.3137\n",
      "Epoch 4 Batch 200 Loss 0.1809 Accuracy 0.3039\n",
      "Epoch 4 Batch 300 Loss 0.1387 Accuracy 0.3137\n",
      "Epoch 4 Batch 344 Loss 0.1294 Accuracy 0.3195\n",
      "Epoch 4 Loss 0.1686 Acc 0.3079\n",
      "Time taken for 1 epoch 81.9140 sec\n",
      "\n",
      "Epoch 4 Batch 0 Val Loss 0.1985 Val Accuracy 0.2875\n",
      "Epoch 4 Batch 33 Val Loss 0.1535 Val Accuracy 0.2914\n",
      "Epoch 4 Val Loss 0.1694 Val Acc 0.2925\n",
      "Time taken for 1 epoch 2.9707 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1475 Accuracy 0.3094\n",
      "Epoch 5 Batch 100 Loss 0.1440 Accuracy 0.3141\n",
      "Epoch 5 Batch 200 Loss 0.1312 Accuracy 0.3160\n",
      "Epoch 5 Batch 300 Loss 0.1261 Accuracy 0.3117\n",
      "Epoch 5 Batch 344 Loss 0.1536 Accuracy 0.3195\n",
      "Epoch 5 Loss 0.1461 Acc 0.3151\n",
      "Time taken for 1 epoch 81.9148 sec\n",
      "\n",
      "Epoch 5 Batch 0 Val Loss 0.1623 Val Accuracy 0.2789\n",
      "Epoch 5 Batch 33 Val Loss 0.1486 Val Accuracy 0.2926\n",
      "Epoch 5 Val Loss 0.1646 Val Acc 0.2941\n",
      "Time taken for 1 epoch 2.9713 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1368 Accuracy 0.3242\n",
      "Epoch 6 Batch 100 Loss 0.1082 Accuracy 0.3090\n",
      "Epoch 6 Batch 200 Loss 0.1193 Accuracy 0.3340\n",
      "Epoch 6 Batch 300 Loss 0.1300 Accuracy 0.3316\n",
      "Epoch 6 Batch 344 Loss 0.1222 Accuracy 0.3070\n",
      "Epoch 6 Loss 0.1309 Acc 0.3198\n",
      "Time taken for 1 epoch 72.4832 sec\n",
      "\n",
      "Epoch 6 Batch 0 Val Loss 0.1447 Val Accuracy 0.2926\n",
      "Epoch 6 Batch 33 Val Loss 0.1747 Val Accuracy 0.2883\n",
      "Epoch 6 Val Loss 0.1585 Val Acc 0.2953\n",
      "Time taken for 1 epoch 2.8303 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0931 Accuracy 0.3230\n",
      "Epoch 7 Batch 100 Loss 0.1198 Accuracy 0.3191\n",
      "Epoch 7 Batch 200 Loss 0.1026 Accuracy 0.3352\n",
      "Epoch 7 Batch 300 Loss 0.1498 Accuracy 0.3168\n",
      "Epoch 7 Batch 344 Loss 0.1088 Accuracy 0.3359\n",
      "Epoch 7 Loss 0.1186 Acc 0.3238\n",
      "Time taken for 1 epoch 81.9150 sec\n",
      "\n",
      "Epoch 7 Batch 0 Val Loss 0.1395 Val Accuracy 0.2930\n",
      "Epoch 7 Batch 33 Val Loss 0.1510 Val Accuracy 0.3051\n",
      "Epoch 7 Val Loss 0.1457 Val Acc 0.3001\n",
      "Time taken for 1 epoch 3.0105 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0979 Accuracy 0.3391\n",
      "Epoch 8 Batch 100 Loss 0.0943 Accuracy 0.3383\n",
      "Epoch 8 Batch 200 Loss 0.1055 Accuracy 0.3242\n",
      "Epoch 8 Batch 300 Loss 0.1042 Accuracy 0.3508\n",
      "Epoch 8 Batch 344 Loss 0.1056 Accuracy 0.3340\n",
      "Epoch 8 Loss 0.1082 Acc 0.3273\n",
      "Time taken for 1 epoch 81.9155 sec\n",
      "\n",
      "Epoch 8 Batch 0 Val Loss 0.1272 Val Accuracy 0.2980\n",
      "Epoch 8 Batch 33 Val Loss 0.1607 Val Accuracy 0.3063\n",
      "Epoch 8 Val Loss 0.1479 Val Acc 0.2999\n",
      "Time taken for 1 epoch 2.9457 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0888 Accuracy 0.3242\n",
      "Epoch 9 Batch 100 Loss 0.1045 Accuracy 0.3242\n",
      "Epoch 9 Batch 200 Loss 0.1017 Accuracy 0.3219\n",
      "Epoch 9 Batch 300 Loss 0.1163 Accuracy 0.3168\n",
      "Epoch 9 Batch 344 Loss 0.1261 Accuracy 0.3238\n",
      "Epoch 9 Loss 0.1000 Acc 0.3300\n",
      "Time taken for 1 epoch 81.9131 sec\n",
      "\n",
      "Epoch 9 Batch 0 Val Loss 0.1659 Val Accuracy 0.2867\n",
      "Epoch 9 Batch 33 Val Loss 0.1424 Val Accuracy 0.3172\n",
      "Epoch 9 Val Loss 0.1595 Val Acc 0.2969\n",
      "Time taken for 1 epoch 2.9884 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1167 Accuracy 0.3227\n",
      "Epoch 10 Batch 100 Loss 0.0874 Accuracy 0.3340\n",
      "Epoch 10 Batch 200 Loss 0.1045 Accuracy 0.3289\n",
      "Epoch 10 Batch 300 Loss 0.0953 Accuracy 0.3367\n",
      "Epoch 10 Batch 344 Loss 0.0861 Accuracy 0.3500\n",
      "Epoch 10 Loss 0.0946 Acc 0.3316\n",
      "Time taken for 1 epoch 81.9156 sec\n",
      "\n",
      "Epoch 10 Batch 0 Val Loss 0.1389 Val Accuracy 0.3145\n",
      "Epoch 10 Batch 33 Val Loss 0.1496 Val Accuracy 0.3059\n",
      "Epoch 10 Val Loss 0.1569 Val Acc 0.2991\n",
      "Time taken for 1 epoch 3.0005 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1127 Accuracy 0.3250\n",
      "Epoch 11 Batch 100 Loss 0.0780 Accuracy 0.3277\n",
      "Epoch 11 Batch 200 Loss 0.0812 Accuracy 0.3383\n",
      "Epoch 11 Batch 300 Loss 0.0942 Accuracy 0.3453\n",
      "Epoch 11 Batch 344 Loss 0.0752 Accuracy 0.3332\n",
      "Epoch 11 Loss 0.0816 Acc 0.3360\n",
      "Time taken for 1 epoch 72.4736 sec\n",
      "\n",
      "Epoch 11 Batch 0 Val Loss 0.1539 Val Accuracy 0.3027\n",
      "Epoch 11 Batch 33 Val Loss 0.1416 Val Accuracy 0.3055\n",
      "Epoch 11 Val Loss 0.1486 Val Acc 0.3016\n",
      "Time taken for 1 epoch 2.8373 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0666 Accuracy 0.3398\n",
      "Epoch 12 Batch 100 Loss 0.0783 Accuracy 0.3402\n",
      "Epoch 12 Batch 200 Loss 0.0729 Accuracy 0.3324\n",
      "Epoch 12 Batch 300 Loss 0.0749 Accuracy 0.3203\n",
      "Epoch 12 Batch 344 Loss 0.0676 Accuracy 0.3266\n",
      "Epoch 12 Loss 0.0792 Acc 0.3366\n",
      "Time taken for 1 epoch 72.2907 sec\n",
      "\n",
      "Epoch 12 Batch 0 Val Loss 0.1511 Val Accuracy 0.3164\n",
      "Epoch 12 Batch 33 Val Loss 0.1649 Val Accuracy 0.2922\n",
      "Epoch 12 Val Loss 0.1461 Val Acc 0.3024\n",
      "Time taken for 1 epoch 2.8705 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0664 Accuracy 0.3324\n",
      "Epoch 13 Batch 100 Loss 0.0718 Accuracy 0.3313\n",
      "Epoch 13 Batch 200 Loss 0.0817 Accuracy 0.3371\n",
      "Epoch 13 Batch 300 Loss 0.0567 Accuracy 0.3355\n",
      "Epoch 13 Batch 344 Loss 0.0661 Accuracy 0.3363\n",
      "Epoch 13 Loss 0.0696 Acc 0.3396\n",
      "Time taken for 1 epoch 72.3590 sec\n",
      "\n",
      "Epoch 13 Batch 0 Val Loss 0.1452 Val Accuracy 0.3082\n",
      "Epoch 13 Batch 33 Val Loss 0.1491 Val Accuracy 0.2926\n",
      "Epoch 13 Val Loss 0.1469 Val Acc 0.3039\n",
      "Time taken for 1 epoch 2.8032 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0551 Accuracy 0.3344\n",
      "Epoch 14 Batch 100 Loss 0.0617 Accuracy 0.3516\n",
      "Epoch 14 Batch 200 Loss 0.1133 Accuracy 0.3238\n",
      "Epoch 14 Batch 300 Loss 0.1277 Accuracy 0.3035\n",
      "Epoch 14 Batch 344 Loss 0.1161 Accuracy 0.3133\n",
      "Epoch 14 Loss 0.1056 Acc 0.3291\n",
      "Time taken for 1 epoch 72.2088 sec\n",
      "\n",
      "Epoch 14 Batch 0 Val Loss 0.1542 Val Accuracy 0.3078\n",
      "Epoch 14 Batch 33 Val Loss 0.1526 Val Accuracy 0.2914\n",
      "Epoch 14 Val Loss 0.1582 Val Acc 0.2971\n",
      "Time taken for 1 epoch 2.8043 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0843 Accuracy 0.3379\n",
      "Epoch 15 Batch 100 Loss 0.0884 Accuracy 0.3422\n",
      "Epoch 15 Batch 200 Loss 0.0814 Accuracy 0.3270\n",
      "Epoch 15 Batch 300 Loss 0.0650 Accuracy 0.3535\n",
      "Epoch 15 Batch 344 Loss 0.0681 Accuracy 0.3262\n",
      "Epoch 15 Loss 0.0830 Acc 0.3348\n",
      "Time taken for 1 epoch 81.9144 sec\n",
      "\n",
      "Epoch 15 Batch 0 Val Loss 0.1414 Val Accuracy 0.3121\n",
      "Epoch 15 Batch 33 Val Loss 0.2194 Val Accuracy 0.2922\n",
      "Epoch 15 Val Loss 0.1470 Val Acc 0.3027\n",
      "Time taken for 1 epoch 2.9284 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0605 Accuracy 0.3320\n",
      "Epoch 16 Batch 100 Loss 0.0640 Accuracy 0.3520\n",
      "Epoch 16 Batch 200 Loss 0.0690 Accuracy 0.3324\n",
      "Epoch 16 Batch 300 Loss 0.0690 Accuracy 0.3441\n",
      "Epoch 16 Batch 344 Loss 0.0666 Accuracy 0.3406\n",
      "Epoch 16 Loss 0.0639 Acc 0.3414\n",
      "Time taken for 1 epoch 81.9147 sec\n",
      "\n",
      "Epoch 16 Batch 0 Val Loss 0.1575 Val Accuracy 0.2883\n",
      "Epoch 16 Batch 33 Val Loss 0.1561 Val Accuracy 0.3055\n",
      "Epoch 16 Val Loss 0.1515 Val Acc 0.3026\n",
      "Time taken for 1 epoch 2.9613 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0488 Accuracy 0.3523\n",
      "Epoch 17 Batch 100 Loss 0.0637 Accuracy 0.3434\n",
      "Epoch 17 Batch 200 Loss 0.0526 Accuracy 0.3406\n",
      "Epoch 17 Batch 300 Loss 0.0679 Accuracy 0.3215\n",
      "Epoch 17 Batch 344 Loss 0.0583 Accuracy 0.3578\n",
      "Epoch 17 Loss 0.0563 Acc 0.3437\n",
      "Time taken for 1 epoch 81.9149 sec\n",
      "\n",
      "Epoch 17 Batch 0 Val Loss 0.1376 Val Accuracy 0.2973\n",
      "Epoch 17 Batch 33 Val Loss 0.1413 Val Accuracy 0.3125\n",
      "Epoch 17 Val Loss 0.1513 Val Acc 0.3031\n",
      "Time taken for 1 epoch 2.9726 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0437 Accuracy 0.3473\n",
      "Epoch 18 Batch 100 Loss 0.0467 Accuracy 0.3512\n",
      "Epoch 18 Batch 200 Loss 0.0406 Accuracy 0.3562\n",
      "Epoch 18 Batch 300 Loss 0.0452 Accuracy 0.3543\n",
      "Epoch 18 Batch 344 Loss 0.0443 Accuracy 0.3473\n",
      "Epoch 18 Loss 0.0481 Acc 0.3466\n",
      "Time taken for 1 epoch 72.2682 sec\n",
      "\n",
      "Epoch 18 Batch 0 Val Loss 0.1833 Val Accuracy 0.2988\n",
      "Epoch 18 Batch 33 Val Loss 0.1627 Val Accuracy 0.2973\n",
      "Epoch 18 Val Loss 0.1586 Val Acc 0.3024\n",
      "Time taken for 1 epoch 2.8382 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0364 Accuracy 0.3344\n",
      "Epoch 19 Batch 100 Loss 0.0464 Accuracy 0.3523\n",
      "Epoch 19 Batch 200 Loss 0.0423 Accuracy 0.3660\n",
      "Epoch 19 Batch 300 Loss 0.0521 Accuracy 0.3609\n",
      "Epoch 19 Batch 344 Loss 0.0664 Accuracy 0.3484\n",
      "Epoch 19 Loss 0.0455 Acc 0.3472\n",
      "Time taken for 1 epoch 81.9143 sec\n",
      "\n",
      "Epoch 19 Batch 0 Val Loss 0.1620 Val Accuracy 0.2875\n",
      "Epoch 19 Batch 33 Val Loss 0.1539 Val Accuracy 0.2953\n",
      "Epoch 19 Val Loss 0.1612 Val Acc 0.3029\n",
      "Time taken for 1 epoch 2.9914 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0316 Accuracy 0.3578\n",
      "Epoch 20 Batch 100 Loss 0.0467 Accuracy 0.3668\n",
      "Epoch 20 Batch 200 Loss 0.0406 Accuracy 0.3465\n",
      "Epoch 20 Batch 300 Loss 0.0478 Accuracy 0.3480\n",
      "Epoch 20 Batch 344 Loss 0.0451 Accuracy 0.3363\n",
      "Epoch 20 Loss 0.0419 Acc 0.3483\n",
      "Time taken for 1 epoch 72.1212 sec\n",
      "\n",
      "Epoch 20 Batch 0 Val Loss 0.1887 Val Accuracy 0.2859\n",
      "Epoch 20 Batch 33 Val Loss 0.1616 Val Accuracy 0.3137\n",
      "Epoch 20 Val Loss 0.1640 Val Acc 0.3039\n",
      "Time taken for 1 epoch 2.8457 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc, dec = train(dataset, test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421ac1f-81fc-4cec-9094-88b21ba143a6",
   "metadata": {
    "id": "6421ac1f-81fc-4cec-9094-88b21ba143a6"
   },
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5643c560-2f13-43ec-aba5-8fd6eb23762a",
   "metadata": {
    "id": "5643c560-2f13-43ec-aba5-8fd6eb23762a"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention_plot = np.zeros((dataset.max_target_seq_length, dataset.max_input_seq_length))\n",
    "\n",
    "    sentence = dataset.preprocess_word(sentence)\n",
    "\n",
    "    inputs = [dataset.input_tokenizer.word_index[i] for i in sentence]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=dataset.max_input_seq_length, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    # hidden = encoder.initialize_hidden_state(1)\n",
    "    hidden = [tf.zeros((1, encoder.enc_units)), tf.zeros((1, encoder.enc_units))]\n",
    "    enc_out, enc_hidden, _ = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([dataset.target_tokenizer.word_index[sos]], 0)\n",
    "\n",
    "    for t in range(dataset.max_target_seq_length):\n",
    "        predictions, dec_hidden, _, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += dataset.target_tokenizer.index_word[predicted_id]\n",
    "\n",
    "        if dataset.target_tokenizer.index_word[predicted_id] == eos:\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bba6377a-ec7d-4c48-8b40-e6e75bd64de3",
   "metadata": {
    "id": "bba6377a-ec7d-4c48-8b40-e6e75bd64de3"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence, inp, res):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    hindi_font = FontProperties(fname = 'Nirmala.ttf')\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=0)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, fontproperties=hindi_font)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.savefig(f\"{inp}.png\")\n",
    "    wandb.log({f\"Q5: Heatmap - {inp}\": wandb.Image(f\"{inp}.png\")})\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9db2c059-3601-459b-b285-08cb6bda4f84",
   "metadata": {
    "id": "9db2c059-3601-459b-b285-08cb6bda4f84"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input:', sentence)\n",
    "    print('Predicted translation:', result)\n",
    "\n",
    "    attention_plot = attention_plot[:len(result), :len(sentence)]\n",
    "    plot_attention(attention_plot, [i for i in sentence], [i for i in result], sentence, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00985e4f-7438-416c-93b0-647556ce517b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "00985e4f-7438-416c-93b0-647556ce517b",
    "outputId": "cd9a650c-06d6-49c7-bb64-994f44a05a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: @shibo#\n",
      "Predicted translation: शिबो#\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAG1CAYAAAAP5HuyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS+ElEQVR4nO3df8zud13f8de7PaenLUHb0Ypj/FSKMLWAHNeV4sKMmUwXMuI02dBZ0J2RxYWN7IebuIWMLOucmzClWmOsZcIydApx0Y5tYWJDhUIBYcEJ0hqEotX+sGVtD+e898d9dav1tH3fP7/X1fvxSE7Odd3Xde7vu5/eP5739/u9vnd1dwAAeGxnLT0AAMCmEE4AAEPCCQBgSDgBAAwJJwCAIeEEADB0aMOpqo5W1aur6vqq+kxV/V5Vvb+qfrCqLlh6Ph6/quo9VfWjS8+x6arq2qr6paXn2DQ+/mB3jiw9wBKq6plJfjFb//0/nuRfJLkrybOT/I0kn6iqV3T3+5aaEXhMr01SSw8BzFXVxUl+N8mFSR5IcmeS53X37yw62DYcunCqqicmuT7Jzyf5gf7jVwD9jSS/UFUvX/39wu7+3BJzAo+uu+9aegZg2y5P8pHuvreqLkvyh5sUTcnhPFT3j5J8uLv/aZInrnb3f66qPlRVV1bVx7v7XUl+MskPLjvqequqv1BVN1bVPVV11+pQ59csPdeGOKuq/mVV3b46TPxvquowfj7umEN1u3Kkqt5UVXes/vyQj7+ZqjpWVT9SVZ+vqvtWXwNfsvRcG+TFSW5Y3X7JQ25vjEO3xynJdyf5ltXtH07yvCTfluT8JD+W5NjqsWuT/FqSv3PA822EqjqS5J1JfirJK5McTfJ1SU4tOdcGeWWSN2Xri8gLkrwtyQeTvH3JoTg0Xpmtr3GXJ7k0Wz8ofi7Jv11wpk3xr5N8R5JXJ/ntJK9L8itVdYkjFGdWVU9P8tHV3fOTnKqqK5Ocl6Sr6s4kb+vujfh+W4fpd9VV1YVJbunuL13d/70kr+juG1b3vzPJG7v7mVV1fpI7uvvYI7/Hw6uq/lSSP0jy0u7+n0vPs0mq6j1JjnX35Q9527uT3Nrd37vYYBumqq5NclF3/5WlZ9kkq4+/pyT5qgdPVaiq1yd5TXc/dcnZ1l1VPSHJHUm+t7uvW73t7CT/O8nbu/v1S863rlY/aD81yZckuSnJ8ST3Jvlwkm9N8jtJ7unu2xcbchsO267Zo0nuf8j9c7L1P+9B9zzk9tcl+eRBDLWJuvsPs/UT6/VV9V+q6nWrnyqY+ejD7n82yZctMQiH0o0PO7/zfUn+TFV9yVIDbYivzNb3kf93eKm7T2Vr/f7sUkOtu+7+YnffkuS5ST7Q3R9N8uVJPt/dv9rdt2xKNCWHL5xuT3K0qv706v6vJvn+qnpCVT0pyd9Lkqr66iRXJ/mhZcbcDN39qiSXZWsdX57kN6vqm5edamOcfNj9zuH7fITHk8Nz+GabqurjVXVPkrcm+XOr2/89yTNX58h+fNkJt+dQfaHu7tPZOi/n+1Zvem22znG6O8kt2fop4hlJfiXJv+/uaw9+ys3S3R/p7qu6+6VJ3pOtc8iA9XZZVT30Ug5/Pslnu/vupQbaEJ/K1kvor3jwDatDdZcn+V9LDbUBviVb53LeluQ7V7c/lq2dFS/I/z/veCMcxpPD35Dkpqp6f3e/M8nzq+rJ2Yqnk0ne3N2fX3TCDVBVz0ryt5O8K1vX5PiKbJ1kevWScwEjT0nyI1X1liRfm+QfJnnjsiOtv9VL6K9OclVV3Z7k00n+fpInJ3nLosOtse6+taq+PFvr9M5s7Z376iQ/v4kn1B+6cOruT1fVX0vyc1X1jmxdAPM3kpxO8pwk31dVT+7u71hyzg3whWyt1zuSXJTk80l+NslVSw4FjPxskrOT/Hq2von9VJJ/t+hEm+Mfr/7+6SQXJLk5ycs2MQAO2EuzdX7TfVX1DUk+s6lrdqheVfdQVfW0bF2n6duy9cF/OltXD397tl5ZZ68TAPDHHNpwetDqom8XZ+unr9tW50EBAPwJhz6cAACmDtWr6gAAdkM4AQAMCScAgCHhBAAwJJySVNWJpWfYZNZv56zd7li/3bF+u2P9dm6T1044bdnY/4FrwvrtnLXbHeu3O9Zvd6zfzm3s2gknAIChA7mO0zl1rM/NE/Z9Ozt1MvfnaI4tPcYjqrPWu28f6PtyTp279BhndPKi85Ye4VF98f/cmyPnre/nxtn3rfd13k4+cG+OnrO+63fWA6eWHuFRPXDqCznn7POXHuOM+v4Hlh7hMZ3s+3J0Tb/2bf0mnfV1su/P0Vrf77t/1Hfc3t0Xn+mxA/lddefmCbns7L90EJt6XDrrvHX9xFx/n/vrz196hI124W+u/zevdXbeZ/5o6RE21ulP3rL0CJvt1HpH+7p798n/eOsjPbbeuzIAANaIcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDA0KOGU1W9pKp6G3+ee1CDAwActEcNp+7+te6uJH8xyW1JnpXkkiQfSfI9q8deleT67q7u/sR+DwwAsJTpobpLktzc3bd09yeT/LMkf2v/xgIAWD/TcHpfkiuq6nhVVZLT+zgTAMBaOjJ5Und/rKr+SZJ3JXlzkpcnuW4/BwMAWDePGU5VdV6S9ye5OMk7klyZ5Je6++rH+HcnkpxIknNz/q4HBQBY2uRQ3QNJfjfJhUlekeRkkjc81j/q7mu6+3h3Hz+aY7ubEgBgDTxmOHX3qe5+WXcfS/LMJB9M8q6qUkMAwKGyrQtgdvcXk7w6yV1JHvVQHQDA4822rxze3aeT/M0kl1XVJXs/EgDAehq9qu7huvvuqnphdz+Q5LeSXLunUwEArKEd/666VTQBABwafskvAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaOHNiW+vSBberx5vS99y49wsZ6ynUfX3qEjXb62U9beoSN9vVv+9jSI2ysG19wztIjwBnZ4wQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAztOpyq6tKqem9V3VNVd1TVL1fVX92L4QAA1sle7HF6a5IbkjwlyfOS/HSS718F1EV78P4BANbCXoTTJUmu7u67u/u27v5PSS5P8gtJbqiqS/dgGwAAizuyB+/jQ0mek+TWB9/Q3Z3kmqr6QJK3ncoX92AzAADL2vEep6p6QVV1kiuS/NequvPhz+num7v7a87ekz4DAFjWjsOpuz/c3ZXkJ5K8obsv2LuxAADWj8sRAAAMCScAgKF9O/moqk4kOZEk5+b8/doMAMCB2bc9Tt19TXcf7+7jR3NsvzYDAHBgHKoDABgSTgAAQ8IJAGBIOAEADO36VXXd/Zq9GAQAYN3Z4wQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAoSMHtqXuA9sUPOjUnXctPcJmu8n67caNzz+69Agb6/rP3rz0CBvtZU8/vvQIm+30Iz9kjxMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDo3Cqqm+qqn6MP7ft97AAAEs6MnlSd/+3JHWmx6rq2iSf6O5/tYdzAQCsnW0dqquqL62qH6+q26rq7qp6a5KL9mk2AIC1st1znH4myYuTfDrJs5J8LMnL9nooAIB1NDpUlyRV9aQkL0/yZUl+Msl3dfdVVfW1+zUcAMA62c4ep/uTnEpyOslrkryuqp6T5CvO9OSqOlFVN1XVTSdz/+4nBQBY2DicuvueJG9J8hNJzk5yVZL3JLn8EZ5/TXcf7+7jR3NsD0YFAFjW+FDdyj9I8vokNyd5YpL3JvnUXg8FALCOtnVyeHef7O5/3t1P7u7zu/ubI5wAgEPClcMBAIa2e6juT+juK/dgDgCAtWePEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwNCRpQcAgIf7y89+8dIjbLQ3f+rdS4+w0Z739Ed+zB4nAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAxtK5yq6oKq6qq6r6p+saou3K/BAADWzbbCqbvv7O5KckGS/5HkHVVlrxUAcCjsKHq6+77ufnOS9yV57d6OBACwnna7t+iNSb67qp62F8MAAKyzHYdTVT0/yb1JLk1yS1V9Zs+mAgBYQzsOp+7+SHcfSXJdkh/o7qfu3VgAAOvHid0AAEPCCQBg6Mh+veOqOpHkRJKcm/P3azMAAAdm3/Y4dfc13X28u48fzbH92gwAwIFxqA4AYEg4AQAMCScAgCHhBAAwtOtX1XX3lXswBwDA2rPHCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDR5YeAAAe7vQXvrD0CBvt7z7jiqVH2HA/94iP2OMEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDA0I7CqapurKonVdULq+rtez0UAMA62nY4VdXZSS7o7j9I8qIkH9rzqQAA1tBO9jg9N8knVrdflOTmvRsHAGB9HZk+saq+PskvJzl3df/2JBck+faq+mx3X7o/IwIArIfxHqfu/kB3X5TkTUletbr9W9190ZmiqapOVNVNVXXTydy/hyMDACxjJ4fqXpTkA1X1lUk+9UhP6u5ruvt4dx8/mmM7HhAAYF2Mw6mq3lpVtyX5piQ3JvlgkpdW1W1V9T37NSAAwLoYn+PU3d9VVU9Ncl13f2NV/XCSG7r7P+/feAAA62O7h+q+IckNq9tXJHnv3o4DALC+xnucVn47yU2r2z/a3b+/x/MAAKytbYVTd//6Q27/h70fBwBgfflddQAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPCCQBgSDgBAAwJJwCAIeEEADAknAAAhoQTAMCQcAIAGBJOAABDwgkAYEg4AQAMCScAgCHhBAAwJJwAAIaEEwDAkHACABgSTgAAQ8IJAGBIOAEADAknAIAh4QQAMCScAACGhBMAwJBwAgAYEk4AAEPV3fu/karfT3Lrvm9o5y5KcvvSQ2ww67dz1m53rN/uWL/dsX47t+5r94zuvvhMDxxIOK27qrqpu48vPcemsn47Z+12x/rtjvXbHeu3c5u8dg7VAQAMCScAgCHhtOWapQfYcNZv56zd7li/3bF+u2P9dm5j1845TgAAQ/Y4AQAMCScAgCHhBAAwJJwAAIaEEwDA0P8FK/+MSJiIiPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"shibo\", enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "zU-lii9njfj4",
   "metadata": {
    "id": "zU-lii9njfj4"
   },
   "outputs": [],
   "source": [
    "def save_predictions(data_frame, name):\n",
    "    accuracy_count = 0;\n",
    "    with open(name, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"INPUT\", \"PREDICTION\", \"TRUE\"])\n",
    "        for i, (inp, trg) in enumerate(zip(data_frame[1], data_frame[0])): \n",
    "            result, sentence, attention_plot = evaluate(inp, enc, dec)\n",
    "            if i < 20:\n",
    "                attention_plot = attention_plot[:len(result), :len(sentence)]\n",
    "                plot_attention(attention_plot, [i for i in sentence], [i for i in result], sentence, result)\n",
    "            writer.writerow([inp, result[:-1], trg])\n",
    "            print(inp, result[:-1], trg)\n",
    "            if result[:-1] == trg:\n",
    "                accuracy_count += 1\n",
    "            if (i+1) % 100 == 0 or i+1 == data_frame.size:\n",
    "                print(\"Accuracy\", (accuracy_count / (i+1)))\n",
    "                wandb.log({\"attn test accuracy\": (accuracy_count / (i+1))})\n",
    "\n",
    "    return accuracy_count/data_frame.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kkzktH4_qvaB",
   "metadata": {
    "id": "kkzktH4_qvaB"
   },
   "outputs": [],
   "source": [
    "# save_predictions(test_df, \"1-new_code_with_attn_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D_5Dushi2L3b",
   "metadata": {
    "id": "D_5Dushi2L3b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "q5-.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
