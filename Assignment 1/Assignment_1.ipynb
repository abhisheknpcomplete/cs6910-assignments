{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "c893e015675f7e258763faa9ddb971e743cc33eb31fe99fe98fc47132504a4a3"
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfwKSjBS7gjF"
      },
      "source": [
        "#CS6910: Deep Learning - Assignment 1: Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufj6q0KF7iVg"
      },
      "source": [
        "Shibobrota Das (CS20M059) | Abhishek Kumar (CS20M007)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "1i_tIKHX6mQk",
        "outputId": "9f4a19b2-950e-4acb-bbf2-d1a572771e74"
      },
      "source": [
        "# !pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.init(project=\"assignment-1\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Finishing last run (ID:1gx0uc8u) before initializing another..."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br/>Waiting for W&B process to finish, PID 13348<br/>Program ended successfully."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find user logs for this run at: <code>c:\\Users\\Shibo\\Downloads\\wandb\\run-20210326_020550-1gx0uc8u\\logs\\debug.log</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find internal logs for this run at: <code>c:\\Users\\Shibo\\Downloads\\wandb\\run-20210326_020550-1gx0uc8u\\logs\\debug-internal.log</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>Accuracy</td><td>0.75531</td></tr><tr><td>Error</td><td>0.24469</td></tr><tr><td>_runtime</td><td>168</td></tr><tr><td>_timestamp</td><td>1616704718</td></tr><tr><td>_step</td><td>1079</td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>Accuracy</td><td>▁▂▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>Error</td><td>█▇▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">divine-firebrand-36</strong>: <a href=\"https://wandb.ai/cs20m059/Assignment%201/runs/1gx0uc8u\" target=\"_blank\">https://wandb.ai/cs20m059/Assignment%201/runs/1gx0uc8u</a><br/>\n                "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "...Successfully finished last run (ID:1gx0uc8u). Initializing new run:<br/><br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n                Tracking run with wandb version 0.10.23<br/>\n                Syncing run <strong style=\"color:#cdcd00\">distinctive-pine-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/cs20m059/assignment-1\" target=\"_blank\">https://wandb.ai/cs20m059/assignment-1</a><br/>\n                Run page: <a href=\"https://wandb.ai/cs20m059/assignment-1/runs/8v5wdftv\" target=\"_blank\">https://wandb.ai/cs20m059/assignment-1/runs/8v5wdftv</a><br/>\n                Run data is saved locally in <code>c:\\Users\\Shibo\\Downloads\\wandb\\run-20210326_021234-8v5wdftv</code><br/><br/>\n            "
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<h1>Run(8v5wdftv)</h1><iframe src=\"https://wandb.ai/cs20m059/assignment-1/runs/8v5wdftv\" style=\"border:none;width:100%;height:400px\"></iframe>",
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x2393eeeb5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egT36ZLO6xbu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from scipy.special import expit, softmax\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z3ex6Fm64WP"
      },
      "source": [
        "(train_x, train_y), (test_x, test_y)= fashion_mnist.load_data()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsbpUWmX7CHV"
      },
      "source": [
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFCsmYT87Z6U"
      },
      "source": [
        "#Reshape 2D Matrix into 1D Vector\n",
        "train_x = np.array(train_x.reshape(len(train_x), 28 ** 2, 1))\n",
        "test_x = np.array(test_x.reshape(len(test_x), 28 ** 2, 1))\n",
        "\n",
        "#Normalizing data\n",
        "train_x = train_x/255.0\n",
        "test_x = test_x/255.0\n",
        "\n",
        "#Splitting Data\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, train_size = 0.9, test_size = 0.1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJEYtSVxeeb"
      },
      "source": [
        "np.shape(train_x[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cytYXKXT8g2t"
      },
      "source": [
        "#Activation function Def\n",
        "\n",
        "def relu(z):\n",
        "  return x * (x > 0)                                           #learnt from https://stackoverflow.com/questions/32109319/how-to-implement-the-relu-function-in-numpy\n",
        "\n",
        "def sigmoid(z):\n",
        "  return expit(z)\n",
        "\n",
        "def tanh(z):\n",
        "  return np.tanh(z)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1fNmYgvOAFk"
      },
      "source": [
        "#Activation function derivative Def\n",
        "\n",
        "def grad_tanh(x):\n",
        "  return 1-(tanh(x) ** 2)\n",
        "\n",
        "def grad_sigmoid(x):\n",
        "  sig_x = sigmoid(x)\n",
        "  return sig_x*(1-sig_x)\n",
        "\n",
        "def grad_relu(x):\n",
        "  temp = 1. * (x > 0)                                          #learnt from https://stackoverflow.com/questions/32109319/how-to-implement-the-relu-function-in-numpy\n",
        "  return temp"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzi7dvnAOQUL"
      },
      "source": [
        "#Type Initialization\n",
        "RANDOM = \"random\"\n",
        "XAVIER = \"xavier\"\n",
        "ZEROES = \"zeroes\"\n",
        "\n",
        "#Definitions\n",
        "\n",
        "def init_weights(type: str, layers):\n",
        "    W = {}\n",
        "    for i in range(1, len(layers)):\n",
        "      if type == RANDOM:\n",
        "        W[i] = np.random.normal(0, 0.5, size=(layers[i], layers[i-1]))\n",
        "      elif type == XAVIER:\n",
        "        W[i] = np.random.uniform(-(1/np.sqrt(layers[i])), (1/np.sqrt(layers[i])), size=(layers[i], layers[i-1]))\n",
        "      else:\n",
        "        W[i] = np.zeros((layers[i], layers[i-1]))\n",
        "    return W\n",
        "\n",
        "def init_bias(type: str, layers):\n",
        "    B = {}\n",
        "    for i in range(1, len(layers)):\n",
        "      if type == RANDOM:\n",
        "        B[i] = np.random.randn(layers[i], 1)\n",
        "      else:\n",
        "        B[i] = np.zeros((layers[i], 1))\n",
        "    return B"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GVTdT4Edn0W"
      },
      "source": [
        "def init_params(type: str, layers):\n",
        "  return init_weights(type, layers), init_bias(type, layers)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmwQA-B1Bi4B"
      },
      "source": [
        "# #Initialize the layer info - number of neurons per layer\n",
        "layers = [6] + [4] * 2 + [2]\n",
        "\n",
        "#Initialize network the parameters\n",
        "W, B = init_params(RANDOM, layers)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8vMm5-MyZF7"
      },
      "source": [
        "#Type Initialization\n",
        "SIGMOID = \"sigmoid\"\n",
        "TAN_H = \"tanh\"\n",
        "RELU = \"relu\"\n",
        "\n",
        "#Definitions\n",
        "\n",
        "def grad(activation: str, pre_act_vector):\n",
        "  #increase precision\n",
        "  pre_act_vector = np.array(pre_act_vector,dtype=np.longdouble)\n",
        "  if activation == TAN_H:\n",
        "    return grad_tanh(pre_act_vector)\n",
        "  elif activation == SIGMOID:\n",
        "    return grad_sigmoid(pre_act_vector)\n",
        "  elif activation == RELU:\n",
        "    return grad_relu(pre_act_vector)\n",
        "  return None\n",
        "\n",
        "def activate(activation: str, pre_act_vector):\n",
        "  #increase precision\n",
        "  pre_act_vector = np.array(pre_act_vector,dtype=np.longdouble)\n",
        "  if activation == TAN_H:\n",
        "    return tanh(pre_act_vector)\n",
        "  elif activation == SIGMOID:\n",
        "    return sigmoid(pre_act_vector)\n",
        "  elif activation == RELU:\n",
        "    return relu(pre_act_vector)\n",
        "  return None"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THwV7rJ6yaT8"
      },
      "source": [
        "#Forward Propagation\n",
        "\n",
        "def forward_propagation(data, activation, W, B, sizes):                         \n",
        "  H = {0:data}\n",
        "  A = {}\n",
        "  L = len(layers)-1\n",
        "  for k in range(1, L):\n",
        "    A[k] = np.matmul(W[k],H[k-1])+B[k]\n",
        "    H[k] = activate(SIGMOID, A[k])\n",
        "    \n",
        "  A[L] = np.matmul(W[L],H[L-1])+B[L]\n",
        "  y_hat = softmax(A[L])\n",
        "  \n",
        "  return H, A, y_hat"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhHEY3hvMfrt"
      },
      "source": [
        "layers = [784,64,64,64, 10]\n",
        "W, B = init_params(RANDOM, layers)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmyM5znASLu2"
      },
      "source": [
        "H, A, y_hat = forward_propagation(train_x[0], SIGMOID, W, B, layers)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WumUqOGI_0Iu"
      },
      "source": [
        "def back_propagation(y, y_hat, A, H, W, layers, activation):\n",
        "  Y = np.array([1 if i == y else 0 for i in range(len(y_hat))]).reshape(np.shape(y_hat))\n",
        "  dW, dB = init_params(ZEROES, layers)\n",
        "  dA = init_bias(ZEROES, layers)\n",
        "  dH = init_bias(ZEROES, layers)\n",
        "  L = len(layers) - 1\n",
        "  dA[L] = -(Y - y_hat)\n",
        "  for i in range(L, 0, -1):\n",
        "    dW[i] = np.dot(dA[i], H[i - 1].T)\n",
        "    dB[i] = dA[i]\n",
        "    if i > 1:\n",
        "      dH[i - 1] = np.dot(W[i].T, dA[i])\n",
        "      dA[i - 1] = np.multiply(dH[i - 1], grad(activation, A[i - 1]))\n",
        "  return dW, dB"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl4iKdwN6BUg"
      },
      "source": [
        "dW, dB = back_propagation(train_y[0],y_hat,A,H,W,layers,SIGMOID)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziWcjTJrO2x5"
      },
      "source": [
        "def cross_entropy_loss(label, y_hat):\n",
        "  return - np.log(y_hat[label][0])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZUUbu9bvTfQ"
      },
      "source": [
        "def squared_error_loss(label, y_hat):\n",
        "  Y = np.array([1 if i == label else 0 for i in range(len(y_hat))]).reshape(np.shape(y_hat))\n",
        "  loss = (Y - y_hat) ** 2\n",
        "  return np.average(loss)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSDyNMwVxngL"
      },
      "source": [
        "squared_error_loss(train_y[0], y_hat)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12763035647215507"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k1Tcng1bxuL7"
      },
      "source": [
        "def momentum_GD(data,label,activation,epochs,layers,eta,init_type,batch_size=1):\n",
        "\n",
        "  gamma = 0.9\n",
        "  W, B = init_params(init_type, layers)\n",
        "  v_W, v_B = init_params(ZEROES, layers)\n",
        "  dW, dB = init_params(ZEROES, layers)\n",
        "  priv_W, priv_B = init_params(ZEROES, layers)\n",
        "  L = len(layers) - 1\n",
        "  counter, ce, se = 0, 0, 0\n",
        "  loss_list = {\"CE\": [], \"SE\": []}\n",
        "  accuracy = 0\n",
        "  for n in range(epochs):\n",
        "    for k in range(len(data)):\n",
        "      H, A, y_hat = forward_propagation(data[k], activation, W, B, layers)\n",
        "      w, b = back_propagation(label[k],y_hat,A,H,W,layers,activation)\n",
        "      for i in range(1, L+1):\n",
        "        dW[i] += w[i]\n",
        "        dB[i] += b[i]\n",
        "\n",
        "      tem = np.argmax(y_hat, axis=0)[0]\n",
        "      if tem == label[k]:\n",
        "        accuracy += 1\n",
        "      counter += 1\n",
        "      if counter % batch_size == 0:\n",
        "        for i in range(1, L+1):\n",
        "          v_W[i] = gamma * priv_W[i] + eta * dW[i]\n",
        "          v_B[i] = gamma * priv_B[i] + eta * dB[i]\n",
        "          W[i] -= v_W[i]\n",
        "          B[i] -= v_B[i]\n",
        "        priv_W = v_W\n",
        "        priv_B = v_B\n",
        "        dW, dB = init_params(ZEROES, layers)\n",
        "        ce = cross_entropy_loss(label[k], y_hat)\n",
        "        se = squared_error_loss(label[k], y_hat)\n",
        "        print(\"Accuracy\", accuracy/counter)\n",
        "        wandb.log({\"MGD Accuracy\": accuracy/counter, \"MGD Error\": 1-(accuracy/counter), \"MGD Cross Entropy\": float(ce)})\n",
        "    \n",
        "    print(\"Epoch\", n,\"Accuracy\", accuracy/counter)\n",
        "  return W, B, loss_list"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "deIHOTrBN8UO",
        "outputId": "fe48ce32-7e15-4e05-bea1-e635fffe4381"
      },
      "source": [
        "layers = [784,64,64,64, 10]\n",
        "eta = 0.001\n",
        "W, B, loss = momentum_GD(train_x, train_y, SIGMOID, 10, layers, eta, RANDOM, 50)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-48-a8bc28f4504d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmomentum_GD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSIGMOID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRANDOM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-47-179cfb47aa8c>\u001b[0m in \u001b[0;36mmomentum_GD\u001b[1;34m(data, label, activation, epochs, layers, eta, init_type, batch_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[0mtem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mtem\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m       \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeMYXkFAu3O9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}